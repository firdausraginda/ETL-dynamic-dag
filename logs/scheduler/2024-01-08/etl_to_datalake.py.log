[2024-01-08T03:16:44.236+0000] {processor.py:161} INFO - Started process (PID=31) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:16:44.238+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:16:44.243+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:16:44.243+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:16:44.365+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:16:44.364+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 9, in <module>
    from rflow.sensors.external_task import ExternalTaskSensor
ModuleNotFoundError: No module named 'rflow'
[2024-01-08T03:16:44.366+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:16:44.399+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.169 seconds
[2024-01-08T03:17:14.870+0000] {processor.py:161} INFO - Started process (PID=90) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:17:14.876+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:17:14.879+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:17:14.878+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:17:14.894+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:17:14.893+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 9, in <module>
    from rflow.sensors.external_task import ExternalTaskSensor
ModuleNotFoundError: No module named 'rflow'
[2024-01-08T03:17:14.894+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:17:14.919+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.054 seconds
[2024-01-08T03:17:45.176+0000] {processor.py:161} INFO - Started process (PID=149) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:17:45.178+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:17:45.180+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:17:45.180+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:17:45.194+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:17:45.193+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 9, in <module>
    from rflow.sensors.external_task import ExternalTaskSensor
ModuleNotFoundError: No module named 'rflow'
[2024-01-08T03:17:45.195+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:17:45.219+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.047 seconds
[2024-01-08T03:18:15.497+0000] {processor.py:161} INFO - Started process (PID=208) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:18:15.500+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:18:15.503+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:18:15.503+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:18:15.517+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:18:15.516+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 9, in <module>
    from rflow.sensors.external_task import ExternalTaskSensor
ModuleNotFoundError: No module named 'rflow'
[2024-01-08T03:18:15.518+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:18:15.544+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.051 seconds
[2024-01-08T03:18:45.893+0000] {processor.py:161} INFO - Started process (PID=267) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:18:45.894+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:18:45.896+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:18:45.896+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:18:45.916+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:18:45.915+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 9, in <module>
    from rflow.sensors.external_task import ExternalTaskSensor
ModuleNotFoundError: No module named 'rflow'
[2024-01-08T03:18:45.917+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:18:45.941+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.053 seconds
[2024-01-08T03:19:16.319+0000] {processor.py:161} INFO - Started process (PID=326) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:19:16.326+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:19:16.329+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:19:16.329+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:19:16.345+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:19:16.344+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 9, in <module>
    from rflow.sensors.external_task import ExternalTaskSensor
ModuleNotFoundError: No module named 'rflow'
[2024-01-08T03:19:16.345+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:19:16.370+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.055 seconds
[2024-01-08T03:19:46.545+0000] {processor.py:161} INFO - Started process (PID=386) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:19:46.547+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:19:46.550+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:19:46.550+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:19:46.565+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:19:46.564+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 9, in <module>
    from rflow.sensors.external_task import ExternalTaskSensor
ModuleNotFoundError: No module named 'rflow'
[2024-01-08T03:19:46.566+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:19:46.590+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.051 seconds
[2024-01-08T03:20:17.011+0000] {processor.py:161} INFO - Started process (PID=445) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:20:17.014+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:20:17.018+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:20:17.017+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:20:17.039+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:20:17.037+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 9, in <module>
    from rflow.sensors.external_task import ExternalTaskSensor
ModuleNotFoundError: No module named 'rflow'
[2024-01-08T03:20:17.039+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:20:17.064+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.057 seconds
[2024-01-08T03:20:47.166+0000] {processor.py:161} INFO - Started process (PID=504) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:20:47.168+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:20:47.171+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:20:47.171+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:20:47.186+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:20:47.185+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 9, in <module>
    from rflow.sensors.external_task import ExternalTaskSensor
ModuleNotFoundError: No module named 'rflow'
[2024-01-08T03:20:47.186+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:20:47.212+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.051 seconds
[2024-01-08T03:21:17.382+0000] {processor.py:161} INFO - Started process (PID=563) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:21:17.384+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:21:17.388+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:21:17.388+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:21:17.410+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:21:17.408+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 9, in <module>
    from rflow.sensors.external_task import ExternalTaskSensor
ModuleNotFoundError: No module named 'rflow'
[2024-01-08T03:21:17.411+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:21:17.442+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.066 seconds
[2024-01-08T03:21:47.805+0000] {processor.py:161} INFO - Started process (PID=623) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:21:47.807+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:21:47.810+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:21:47.810+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:21:47.825+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:21:47.824+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 9, in <module>
    from rflow.sensors.external_task import ExternalTaskSensor
ModuleNotFoundError: No module named 'rflow'
[2024-01-08T03:21:47.826+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:21:47.851+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.051 seconds
[2024-01-08T03:22:18.187+0000] {processor.py:161} INFO - Started process (PID=688) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:22:18.188+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:22:18.191+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:22:18.190+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:22:18.206+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:22:18.205+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 9, in <module>
    from rflow.sensors.external_task import ExternalTaskSensor
ModuleNotFoundError: No module named 'rflow'
[2024-01-08T03:22:18.206+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:22:18.230+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.049 seconds
[2024-01-08T03:25:36.837+0000] {processor.py:161} INFO - Started process (PID=30) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:25:36.842+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:25:36.855+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:25:36.848+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:25:38.347+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:25:38.345+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 117, in <module>
    dict_config = get_config_yaml(path_config_yaml)
  File "/opt/airflow/dags/etl_to_datalake.py", line 71, in get_config_yaml
    dict_config["destination_table"] = dict_yaml.get("destination_table")
NameError: name 'dict_config' is not defined
[2024-01-08T03:25:38.348+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:25:38.379+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.553 seconds
[2024-01-08T03:26:08.984+0000] {processor.py:161} INFO - Started process (PID=90) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:26:08.987+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:26:08.991+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:26:08.990+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:26:09.778+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:26:09.777+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 117, in <module>
    dict_config = get_config_yaml(path_config_yaml)
  File "/opt/airflow/dags/etl_to_datalake.py", line 71, in get_config_yaml
    dict_config["destination_table"] = dict_yaml.get("destination_table")
NameError: name 'dict_config' is not defined
[2024-01-08T03:26:09.779+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:26:09.804+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.826 seconds
[2024-01-08T03:26:39.977+0000] {processor.py:161} INFO - Started process (PID=150) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:26:39.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:26:39.980+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:26:39.980+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:26:40.684+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:26:40.683+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 117, in <module>
    dict_config = get_config_yaml(path_config_yaml)
  File "/opt/airflow/dags/etl_to_datalake.py", line 71, in get_config_yaml
    dict_config["destination_table"] = dict_yaml.get("destination_table")
NameError: name 'dict_config' is not defined
[2024-01-08T03:26:40.685+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:26:40.704+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.733 seconds
[2024-01-08T03:27:10.870+0000] {processor.py:161} INFO - Started process (PID=210) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:27:10.877+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:27:10.881+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:27:10.881+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:27:11.735+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:27:11.734+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 117, in <module>
    dict_config = get_config_yaml(path_config_yaml)
  File "/opt/airflow/dags/etl_to_datalake.py", line 71, in get_config_yaml
    dict_config["destination_table"] = dict_yaml.get("destination_table")
NameError: name 'dict_config' is not defined
[2024-01-08T03:27:11.736+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:27:11.758+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.894 seconds
[2024-01-08T03:27:42.354+0000] {processor.py:161} INFO - Started process (PID=270) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:27:42.357+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:27:42.360+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:27:42.360+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:27:43.056+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:27:43.054+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 117, in <module>
    dict_config = get_config_yaml(path_config_yaml)
  File "/opt/airflow/dags/etl_to_datalake.py", line 71, in get_config_yaml
    dict_config["destination_table"] = dict_yaml.get("destination_table")
NameError: name 'dict_config' is not defined
[2024-01-08T03:27:43.056+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:27:43.076+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.727 seconds
[2024-01-08T03:28:03.204+0000] {processor.py:161} INFO - Started process (PID=330) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:28:03.206+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:28:03.210+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:28:03.210+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:28:03.914+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:28:03.912+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 119, in <module>
    dict_config = get_config_yaml(path_config_yaml)
  File "/opt/airflow/dags/etl_to_datalake.py", line 73, in get_config_yaml
    dict_config["destination_table"] = dict_yaml.get("destination_table")
NameError: name 'dict_config' is not defined
[2024-01-08T03:28:03.914+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:28:03.935+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.736 seconds
[2024-01-08T03:28:05.858+0000] {processor.py:161} INFO - Started process (PID=332) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:28:05.859+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:28:05.862+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:28:05.862+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:28:06.589+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:28:06.588+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 119, in <module>
    dict_config = get_config_yaml(path_config_yaml)
  File "/opt/airflow/dags/etl_to_datalake.py", line 72, in get_config_yaml
    dict_config
NameError: name 'dict_config' is not defined
[2024-01-08T03:28:06.590+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:28:06.611+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.759 seconds
[2024-01-08T03:28:08.656+0000] {processor.py:161} INFO - Started process (PID=334) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:28:08.657+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:28:08.660+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:28:08.660+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:28:09.357+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:28:09.355+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 130, in <module>
    if external_task_dependency:
NameError: name 'external_task_dependency' is not defined
[2024-01-08T03:28:09.357+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:28:09.378+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.728 seconds
[2024-01-08T03:28:39.622+0000] {processor.py:161} INFO - Started process (PID=394) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:28:39.624+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:28:39.627+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:28:39.627+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:28:40.347+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:28:40.346+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 130, in <module>
    if external_task_dependency:
NameError: name 'external_task_dependency' is not defined
[2024-01-08T03:28:40.347+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:28:40.368+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.751 seconds
[2024-01-08T03:28:48.208+0000] {processor.py:161} INFO - Started process (PID=433) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:28:48.211+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:28:48.215+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:28:48.215+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:28:48.991+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:28:48.989+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 115, in <module>
    if external_task_dependency:
NameError: name 'external_task_dependency' is not defined
[2024-01-08T03:28:48.992+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:28:49.015+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.813 seconds
[2024-01-08T03:29:04.018+0000] {processor.py:161} INFO - Started process (PID=455) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:29:04.021+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:29:04.024+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:29:04.024+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:29:04.739+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:29:04.737+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 126, in <module>
    if internal_task_dependency:
NameError: name 'internal_task_dependency' is not defined
[2024-01-08T03:29:04.739+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:29:04.759+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.746 seconds
[2024-01-08T03:29:11.629+0000] {processor.py:161} INFO - Started process (PID=457) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:29:11.632+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:29:11.636+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:29:11.636+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:29:12.365+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:29:12.363+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 128, in <module>
    task_process_datalake.set_upstream(internal_task_dependency)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    task_object.update_relative(self, not upstream, edge_modifier=edge_modifier)
AttributeError: 'str' object has no attribute 'update_relative'
[2024-01-08T03:29:12.365+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:29:12.388+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.763 seconds
[2024-01-08T03:29:42.824+0000] {processor.py:161} INFO - Started process (PID=517) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:29:42.827+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:29:42.830+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:29:42.830+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:29:43.552+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:29:43.550+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 128, in <module>
    task_process_datalake.set_upstream(internal_task_dependency)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    task_object.update_relative(self, not upstream, edge_modifier=edge_modifier)
AttributeError: 'str' object has no attribute 'update_relative'
[2024-01-08T03:29:43.552+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:29:43.573+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.754 seconds
[2024-01-08T03:29:49.383+0000] {processor.py:161} INFO - Started process (PID=558) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:29:49.386+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:29:49.389+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:29:49.388+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:29:50.149+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:29:50.277+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:29:50.276+0000] {override.py:1769} INFO - Created Permission View: can read on DAG:etl_to_datalake
[2024-01-08T03:29:50.289+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:29:50.289+0000] {override.py:1769} INFO - Created Permission View: can edit on DAG:etl_to_datalake
[2024-01-08T03:29:50.298+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:29:50.297+0000] {override.py:1769} INFO - Created Permission View: can delete on DAG:etl_to_datalake
[2024-01-08T03:29:50.299+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:29:50.298+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:29:50.313+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:29:50.312+0000] {dag.py:3055} INFO - Creating ORM DAG for etl_to_datalake
[2024-01-08T03:29:50.328+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:29:50.328+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:29:50.353+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.975 seconds
[2024-01-08T03:30:20.401+0000] {processor.py:161} INFO - Started process (PID=625) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:30:20.403+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:30:20.406+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:30:20.406+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:30:21.188+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:30:21.209+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:30:21.208+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:30:21.236+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:30:21.236+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:30:21.263+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.868 seconds
[2024-01-08T03:30:51.883+0000] {processor.py:161} INFO - Started process (PID=686) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:30:51.884+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:30:51.888+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:30:51.887+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:30:52.679+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:30:52.704+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:30:52.703+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:30:52.740+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:30:52.740+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:30:52.777+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.899 seconds
[2024-01-08T03:31:22.928+0000] {processor.py:161} INFO - Started process (PID=746) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:31:22.929+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:31:22.934+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:31:22.934+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:31:23.878+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:31:23.908+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:31:23.907+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:31:23.941+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:31:23.941+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:31:23.965+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.047 seconds
[2024-01-08T03:31:54.098+0000] {processor.py:161} INFO - Started process (PID=808) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:31:54.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:31:54.103+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:31:54.103+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:31:54.804+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:31:54.825+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:31:54.825+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:31:54.850+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:31:54.850+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:31:54.871+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.779 seconds
[2024-01-08T03:32:25.211+0000] {processor.py:161} INFO - Started process (PID=868) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:32:25.214+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:32:25.218+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:32:25.218+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:32:26.129+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:32:26.157+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:32:26.156+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:32:26.196+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:32:26.196+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:32:26.222+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.018 seconds
[2024-01-08T03:32:56.369+0000] {processor.py:161} INFO - Started process (PID=932) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:32:56.370+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:32:56.373+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:32:56.373+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:32:57.087+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:32:57.108+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:32:57.107+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:32:57.133+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:32:57.133+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:32:57.155+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.791 seconds
[2024-01-08T03:33:27.489+0000] {processor.py:161} INFO - Started process (PID=996) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:33:27.491+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:33:27.494+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:33:27.494+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:33:28.195+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:33:28.215+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:33:28.215+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:33:28.241+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:33:28.240+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:33:28.263+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.780 seconds
[2024-01-08T03:33:58.466+0000] {processor.py:161} INFO - Started process (PID=1056) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:33:58.467+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:33:58.471+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:33:58.470+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:33:59.160+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:33:59.181+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:33:59.180+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:33:59.205+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:33:59.205+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:33:59.227+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.767 seconds
[2024-01-08T03:34:29.789+0000] {processor.py:161} INFO - Started process (PID=1112) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:34:29.791+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:34:29.794+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:34:29.794+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:34:30.507+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:34:30.530+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:34:30.529+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:34:30.554+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:34:30.554+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:34:30.576+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.792 seconds
[2024-01-08T03:35:01.553+0000] {processor.py:161} INFO - Started process (PID=1176) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:35:01.556+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:35:01.560+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:35:01.560+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:35:02.259+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:35:02.280+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:35:02.279+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:35:02.305+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:35:02.305+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:35:02.328+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.781 seconds
[2024-01-08T03:35:32.740+0000] {processor.py:161} INFO - Started process (PID=1236) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:35:32.741+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:35:32.744+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:35:32.744+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:35:33.514+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:35:33.535+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:35:33.534+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:35:33.560+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:35:33.560+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:35:33.583+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.849 seconds
[2024-01-08T03:36:04.431+0000] {processor.py:161} INFO - Started process (PID=1296) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:36:04.434+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:36:04.438+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:36:04.438+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:36:05.271+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:36:05.295+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:36:05.295+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:36:05.320+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:36:05.320+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:36:05.342+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.917 seconds
[2024-01-08T03:36:35.679+0000] {processor.py:161} INFO - Started process (PID=1356) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:36:35.681+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:36:35.684+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:36:35.684+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:36:36.391+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:36:36.412+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:36:36.411+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:36:36.437+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:36:36.437+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:36:36.460+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.786 seconds
[2024-01-08T03:37:07.422+0000] {processor.py:161} INFO - Started process (PID=1416) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:37:07.425+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:37:07.428+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:37:07.428+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:37:08.132+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:37:08.152+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:37:08.152+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:37:08.177+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:37:08.177+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:37:08.200+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.784 seconds
[2024-01-08T03:37:25.152+0000] {processor.py:161} INFO - Started process (PID=1445) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:37:25.155+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:37:25.157+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:37:25.157+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:37:25.860+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:37:25.880+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:37:25.879+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:37:25.907+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:37:25.906+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:37:25.930+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.782 seconds
[2024-01-08T03:37:29.914+0000] {processor.py:161} INFO - Started process (PID=1461) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:37:29.916+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:37:29.919+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:37:29.918+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:37:30.645+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:37:30.643+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 107, in <module>
    list_task_process_datalake
NameError: name 'list_task_process_datalake' is not defined
[2024-01-08T03:37:30.645+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:37:30.666+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.757 seconds
[2024-01-08T03:37:31.714+0000] {processor.py:161} INFO - Started process (PID=1464) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:37:31.715+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:37:31.718+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:37:31.718+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:37:32.408+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:37:32.429+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:37:32.429+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:37:32.455+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:37:32.454+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:37:32.482+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.773 seconds
[2024-01-08T03:37:32.853+0000] {processor.py:161} INFO - Started process (PID=1466) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:37:32.854+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:37:32.857+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:37:32.857+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:37:33.547+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:37:33.568+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:37:33.567+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:37:33.593+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:37:33.592+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:37:33.620+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.773 seconds
[2024-01-08T03:38:03.908+0000] {processor.py:161} INFO - Started process (PID=1526) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:38:03.911+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:38:03.914+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:38:03.914+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:38:04.703+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:38:04.726+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:38:04.725+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:38:04.752+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:38:04.752+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:38:04.777+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.874 seconds
[2024-01-08T03:38:35.604+0000] {processor.py:161} INFO - Started process (PID=1586) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:38:35.605+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:38:35.610+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:38:35.609+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:38:36.527+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:38:36.549+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:38:36.548+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:38:36.574+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:38:36.574+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:38:36.595+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.001 seconds
[2024-01-08T03:39:07.150+0000] {processor.py:161} INFO - Started process (PID=1650) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:39:07.152+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:39:07.155+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:39:07.155+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:39:07.869+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:39:07.892+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:39:07.891+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:39:07.920+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:39:07.919+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:39:07.943+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.798 seconds
[2024-01-08T03:39:38.455+0000] {processor.py:161} INFO - Started process (PID=1710) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:39:38.457+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:39:38.460+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:39:38.459+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:39:39.242+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:39:39.266+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:39:39.265+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:39:39.297+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:39:39.297+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:39:39.320+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.870 seconds
[2024-01-08T03:39:49.615+0000] {processor.py:161} INFO - Started process (PID=1732) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:39:49.618+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:39:49.621+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:39:49.620+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:39:50.344+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:39:50.367+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:39:50.366+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:39:50.393+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:39:50.393+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:39:50.415+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.805 seconds
[2024-01-08T03:39:51.009+0000] {processor.py:161} INFO - Started process (PID=1734) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:39:51.010+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:39:51.013+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:39:51.013+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:39:51.728+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:39:51.749+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:39:51.748+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:39:51.774+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:39:51.774+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:39:51.800+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.795 seconds
[2024-01-08T03:39:53.849+0000] {processor.py:161} INFO - Started process (PID=1736) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:39:53.851+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:39:53.855+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:39:53.854+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:39:54.725+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:39:54.752+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:39:54.751+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:39:54.781+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:39:54.781+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:39:54.805+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.962 seconds
[2024-01-08T03:40:09.320+0000] {processor.py:161} INFO - Started process (PID=1776) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:09.321+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:40:09.325+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:09.325+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:10.151+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:10.150+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 116, in <module>
    list_task_process_datalake.append()
TypeError: append() takes exactly one argument (0 given)
[2024-01-08T03:40:10.152+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:10.172+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.861 seconds
[2024-01-08T03:40:14.193+0000] {processor.py:161} INFO - Started process (PID=1790) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:14.194+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:40:14.197+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:14.196+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:14.885+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:14.906+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:14.905+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:40:14.930+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:14.930+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:40:14.954+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.767 seconds
[2024-01-08T03:40:22.471+0000] {processor.py:161} INFO - Started process (PID=1800) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:22.474+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:40:22.477+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:22.477+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:23.172+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:23.192+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:23.192+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:40:23.217+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:23.216+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:40:23.238+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.772 seconds
[2024-01-08T03:40:24.287+0000] {processor.py:161} INFO - Started process (PID=1802) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:24.289+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:40:24.292+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:24.292+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:25.125+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:25.150+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:25.149+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:40:25.181+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:25.181+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:40:25.214+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.933 seconds
[2024-01-08T03:40:28.699+0000] {processor.py:161} INFO - Started process (PID=1823) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:28.700+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:40:28.703+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:28.703+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:29.412+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:29.433+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:29.433+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:40:29.466+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:29.465+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:40:29.495+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.802 seconds
[2024-01-08T03:40:41.075+0000] {processor.py:161} INFO - Started process (PID=1854) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:41.076+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:40:41.079+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:41.079+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:41.083+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:41.083+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 129
    for
       ^
SyntaxError: invalid syntax
[2024-01-08T03:40:41.084+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:41.110+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.040 seconds
[2024-01-08T03:40:44.887+0000] {processor.py:161} INFO - Started process (PID=1857) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:44.888+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:40:44.891+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:44.891+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:44.896+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:44.895+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 129
    for        list_task_process_datalake.append(task_process_datalake)
                                                                      ^
SyntaxError: invalid syntax
[2024-01-08T03:40:44.896+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:44.925+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.044 seconds
[2024-01-08T03:40:45.900+0000] {processor.py:161} INFO - Started process (PID=1858) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:45.902+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:40:45.905+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:45.905+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:45.910+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:45.909+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 129
    for        list_task_process_datalake.append(task_process_datalake):
                                                                       ^
SyntaxError: invalid syntax
[2024-01-08T03:40:45.910+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:45.937+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.041 seconds
[2024-01-08T03:40:47.540+0000] {processor.py:161} INFO - Started process (PID=1861) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:47.541+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:40:47.544+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:47.544+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:47.549+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:47.548+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 129
    for
       ^
SyntaxError: invalid syntax
[2024-01-08T03:40:47.549+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:47.576+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.040 seconds
[2024-01-08T03:40:51.566+0000] {processor.py:161} INFO - Started process (PID=1868) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:51.567+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:40:51.570+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:51.570+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:51.575+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:51.574+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 129
    for list_task_process_datalake
                                 ^
SyntaxError: invalid syntax
[2024-01-08T03:40:51.575+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:51.602+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.041 seconds
[2024-01-08T03:40:58.950+0000] {processor.py:161} INFO - Started process (PID=1888) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:58.952+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:40:58.956+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:58.956+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:58.961+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:40:58.960+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 135
    
    ^
SyntaxError: unexpected EOF while parsing
[2024-01-08T03:40:58.961+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:40:58.986+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.042 seconds
[2024-01-08T03:41:22.916+0000] {processor.py:161} INFO - Started process (PID=1928) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:41:22.918+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:41:22.921+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:41:22.921+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:41:23.643+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:41:23.664+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:41:23.663+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:41:23.688+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:41:23.688+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:41:23.713+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.802 seconds
[2024-01-08T03:41:24.251+0000] {processor.py:161} INFO - Started process (PID=1930) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:41:24.252+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:41:24.255+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:41:24.255+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:41:24.956+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:41:24.977+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:41:24.976+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:41:25.003+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:41:25.003+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:41:25.032+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.786 seconds
[2024-01-08T03:41:40.927+0000] {processor.py:161} INFO - Started process (PID=1970) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:41:40.930+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:41:40.935+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:41:40.934+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:41:41.670+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:41:41.693+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:41:41.692+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:41:41.717+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:41:41.717+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:41:41.742+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.821 seconds
[2024-01-08T03:42:12.190+0000] {processor.py:161} INFO - Started process (PID=2032) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:42:12.192+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:42:12.195+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:42:12.195+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:42:12.928+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:42:12.951+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:42:12.950+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:42:12.977+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:42:12.977+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:42:13.001+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.816 seconds
[2024-01-08T03:42:26.599+0000] {processor.py:161} INFO - Started process (PID=2053) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:42:26.602+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:42:26.605+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:42:26.604+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:42:27.342+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:42:27.367+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:42:27.367+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:42:27.396+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:42:27.396+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:42:27.423+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.829 seconds
[2024-01-08T03:42:56.148+0000] {processor.py:161} INFO - Started process (PID=2113) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:42:56.149+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:42:56.153+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:42:56.152+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:42:56.847+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:42:56.872+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:42:56.871+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:42:56.902+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:42:56.901+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:42:56.927+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.785 seconds
[2024-01-08T03:43:01.425+0000] {processor.py:161} INFO - Started process (PID=2134) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:01.428+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:43:01.433+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:43:01.432+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:02.187+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:02.214+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:43:02.213+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:43:02.243+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:43:02.243+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:43:02.271+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.851 seconds
[2024-01-08T03:43:09.173+0000] {processor.py:161} INFO - Started process (PID=2151) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:09.174+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:43:09.177+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:43:09.177+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:09.879+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:09.901+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:43:09.900+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:43:09.926+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:43:09.925+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:43:09.950+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.782 seconds
[2024-01-08T03:43:14.277+0000] {processor.py:161} INFO - Started process (PID=2159) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:14.278+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:43:14.281+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:43:14.281+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:15.002+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:15.024+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:43:15.023+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:43:15.062+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:43:15.061+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:43:15.096+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.825 seconds
[2024-01-08T03:43:23.102+0000] {processor.py:161} INFO - Started process (PID=2179) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:23.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:43:23.107+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:43:23.107+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:23.794+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:23.813+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:43:23.813+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:43:23.837+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:43:23.837+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:43:23.862+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.766 seconds
[2024-01-08T03:43:41.989+0000] {processor.py:161} INFO - Started process (PID=2219) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:41.991+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:43:41.996+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:43:41.996+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:42.000+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:43:42.000+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 132
    internal_task_depen_from_task_datalake = [in list_task_datalake]
                                              ^
SyntaxError: invalid syntax
[2024-01-08T03:43:42.001+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:42.028+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.045 seconds
[2024-01-08T03:43:45.132+0000] {processor.py:161} INFO - Started process (PID=2222) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:45.134+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:43:45.138+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:43:45.137+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:45.144+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:43:45.143+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 132
    internal_task_depen_from_task_datalake = [for  in list_task_datalake]
                                              ^
SyntaxError: invalid syntax
[2024-01-08T03:43:45.144+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:45.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.042 seconds
[2024-01-08T03:43:48.554+0000] {processor.py:161} INFO - Started process (PID=2231) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:48.555+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:43:48.558+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:43:48.558+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:48.562+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:43:48.561+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 132
    internal_task_depen_from_task_datalake = [for task_datalake in list_task_datalake]
                                              ^
SyntaxError: invalid syntax
[2024-01-08T03:43:48.563+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:48.587+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.038 seconds
[2024-01-08T03:43:55.194+0000] {processor.py:161} INFO - Started process (PID=2242) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:55.195+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:43:55.198+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:43:55.198+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:55.892+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:55.913+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:43:55.912+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:43:55.940+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:43:55.939+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:43:55.964+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.775 seconds
[2024-01-08T03:43:58.010+0000] {processor.py:161} INFO - Started process (PID=2244) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:58.012+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:43:58.015+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:43:58.015+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:58.940+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:43:58.962+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:43:58.961+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:43:58.994+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:43:58.994+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:43:59.017+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.013 seconds
[2024-01-08T03:44:04.364+0000] {processor.py:161} INFO - Started process (PID=2268) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:04.366+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:44:04.370+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:44:04.369+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:05.160+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:05.182+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:44:05.182+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:44:05.210+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:44:05.210+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:44:05.238+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.879 seconds
[2024-01-08T03:44:10.435+0000] {processor.py:161} INFO - Started process (PID=2282) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:10.436+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:44:10.439+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:44:10.439+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:10.971+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:10.996+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:44:10.995+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:44:11.023+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:44:11.023+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:44:11.049+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.619 seconds
[2024-01-08T03:44:12.103+0000] {processor.py:161} INFO - Started process (PID=2285) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:12.104+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:44:12.108+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:44:12.108+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:12.113+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:44:12.112+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 132
    internal_task_depen_from_task_datalake = [task_datalake for task_datalake in list_task_datalake if task_datalake["task_id"] == ]
                                                                                                                                   ^
SyntaxError: invalid syntax
[2024-01-08T03:44:12.113+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:12.139+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.042 seconds
[2024-01-08T03:44:15.508+0000] {processor.py:161} INFO - Started process (PID=2291) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:15.510+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:44:15.513+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:44:15.513+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:16.066+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:16.090+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:44:16.089+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:44:16.123+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:44:16.123+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:44:16.165+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.662 seconds
[2024-01-08T03:44:22.175+0000] {processor.py:161} INFO - Started process (PID=2311) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:22.176+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:44:22.179+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:44:22.178+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:22.699+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:22.724+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:44:22.723+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:44:22.754+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:44:22.754+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:44:22.778+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.609 seconds
[2024-01-08T03:44:26.692+0000] {processor.py:161} INFO - Started process (PID=2313) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:26.693+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:44:26.696+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:44:26.696+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:26.700+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:44:26.700+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 132
    internal_task_depen_from_task_datalake = [task_datalake for task_datalake in list_task_datalake \
                                                                                                     ^
SyntaxError: unexpected character after line continuation character
[2024-01-08T03:44:26.701+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:26.727+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.040 seconds
[2024-01-08T03:44:27.703+0000] {processor.py:161} INFO - Started process (PID=2314) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:27.704+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:44:27.707+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:44:27.707+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:27.712+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:44:27.711+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 132
    internal_task_depen_from_task_datalake = [task_datalake for task_datalake in list_task_datalake \
                                                                                                     ^
SyntaxError: unexpected character after line continuation character
[2024-01-08T03:44:27.712+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:27.737+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.038 seconds
[2024-01-08T03:44:33.008+0000] {processor.py:161} INFO - Started process (PID=2331) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:33.010+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:44:33.014+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:44:33.013+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:33.021+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:44:33.019+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 132
    internal_task_depen_from_task_datalake = [task_datalake \for task_datalake in list_task_datalake \
                                                                                                      ^
SyntaxError: unexpected character after line continuation character
[2024-01-08T03:44:33.021+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:33.052+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.051 seconds
[2024-01-08T03:44:34.539+0000] {processor.py:161} INFO - Started process (PID=2338) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:34.541+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:44:34.544+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:44:34.543+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:34.548+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:44:34.547+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 133
    internal_task_depen_from_task_datalake = [task_datalake \
                    for task_datalake in list_task_datalake \
                                                             
                                                             ^
SyntaxError: unexpected character after line continuation character
[2024-01-08T03:44:34.549+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:34.576+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.041 seconds
[2024-01-08T03:44:39.703+0000] {processor.py:161} INFO - Started process (PID=2351) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:39.704+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:44:39.707+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:44:39.707+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:39.712+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:44:39.711+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 133
    internal_task_depen_from_task_datalake = [task_datalake \
                    for task_datalake in list_task_datalake \
                                                             
                                                             ^
SyntaxError: unexpected character after line continuation character
[2024-01-08T03:44:39.712+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:44:39.741+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.043 seconds
[2024-01-08T03:45:09.880+0000] {processor.py:161} INFO - Started process (PID=2410) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:45:09.883+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:45:09.887+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:45:09.887+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:45:09.893+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:45:09.892+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 133
    internal_task_depen_from_task_datalake = [task_datalake \
                    for task_datalake in list_task_datalake \
                                                             
                                                             ^
SyntaxError: unexpected character after line continuation character
[2024-01-08T03:45:09.893+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:45:09.921+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.046 seconds
[2024-01-08T03:45:40.148+0000] {processor.py:161} INFO - Started process (PID=2469) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:45:40.150+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:45:40.153+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:45:40.152+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:45:40.157+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:45:40.156+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 133
    internal_task_depen_from_task_datalake = [task_datalake \
                    for task_datalake in list_task_datalake \
                                                             
                                                             ^
SyntaxError: unexpected character after line continuation character
[2024-01-08T03:45:40.158+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:45:40.183+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.039 seconds
[2024-01-08T03:46:10.231+0000] {processor.py:161} INFO - Started process (PID=2529) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:46:10.234+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:46:10.235+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:46:10.234+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:46:10.241+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:46:10.239+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 133
    internal_task_depen_from_task_datalake = [task_datalake \
                    for task_datalake in list_task_datalake \
                                                             
                                                             ^
SyntaxError: unexpected character after line continuation character
[2024-01-08T03:46:10.242+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:46:10.274+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.048 seconds
[2024-01-08T03:46:40.325+0000] {processor.py:161} INFO - Started process (PID=2588) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:46:40.327+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:46:40.327+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:46:40.327+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:46:40.332+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:46:40.331+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 133
    internal_task_depen_from_task_datalake = [task_datalake \
                    for task_datalake in list_task_datalake \
                                                             
                                                             ^
SyntaxError: unexpected character after line continuation character
[2024-01-08T03:46:40.333+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:46:40.359+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.038 seconds
[2024-01-08T03:46:58.994+0000] {processor.py:161} INFO - Started process (PID=2613) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:46:58.996+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:46:58.998+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:46:58.997+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:46:59.002+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:46:59.001+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 133
    internal_task_depen_from_task_datalake = [task_datalake \
                    for task_datalake in list_task_datalake \
                                                             
                                                             ^
SyntaxError: unexpected character after line continuation character
[2024-01-08T03:46:59.003+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:46:59.027+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.038 seconds
[2024-01-08T03:47:29.247+0000] {processor.py:161} INFO - Started process (PID=2672) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:47:29.249+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:47:29.250+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:47:29.249+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:47:29.254+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:47:29.253+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 133
    internal_task_depen_from_task_datalake = [task_datalake \
                    for task_datalake in list_task_datalake \
                                                             
                                                             ^
SyntaxError: unexpected character after line continuation character
[2024-01-08T03:47:29.255+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:47:29.280+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.037 seconds
[2024-01-08T03:47:59.618+0000] {processor.py:161} INFO - Started process (PID=2731) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:47:59.621+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:47:59.622+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:47:59.622+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:47:59.627+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:47:59.626+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 133
    internal_task_depen_from_task_datalake = [task_datalake \
                    for task_datalake in list_task_datalake \
                                                             
                                                             ^
SyntaxError: unexpected character after line continuation character
[2024-01-08T03:47:59.628+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:47:59.653+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.041 seconds
[2024-01-08T03:48:19.990+0000] {processor.py:161} INFO - Started process (PID=2779) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:48:19.991+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:48:19.992+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:48:19.992+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:48:19.997+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:48:19.996+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 134
    internal_task_depen_from_task_datalake = [task_datalake \
                    for task_datalake in list_task_datalake \
                    task_datalake["task_id"] == internal_task_dependency]
        ^
SyntaxError: invalid syntax
[2024-01-08T03:48:19.997+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:48:20.024+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.038 seconds
[2024-01-08T03:48:23.052+0000] {processor.py:161} INFO - Started process (PID=2786) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:48:23.053+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:48:23.054+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:48:23.054+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:48:23.061+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:48:23.060+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 133
    internal_task_depen_from_task_datalake = [task_datalake for task_datalake in list_task_datalake \
                    task_datalake["task_id"] == internal_task_dependency]
        ^
SyntaxError: invalid syntax
[2024-01-08T03:48:23.062+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:48:23.090+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.046 seconds
[2024-01-08T03:48:27.145+0000] {processor.py:161} INFO - Started process (PID=2788) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:48:27.147+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:48:27.149+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:48:27.148+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:48:27.154+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:48:27.153+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 132
    internal_task_depen_from_task_datalake = [task_datalake for task_datalake in list_task_datalake task_datalake["task_id"] == internal_task_dependency]
                                                                                                    ^
SyntaxError: invalid syntax
[2024-01-08T03:48:27.155+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:48:27.179+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.039 seconds
[2024-01-08T03:48:41.577+0000] {processor.py:161} INFO - Started process (PID=2827) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:48:41.580+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:48:41.581+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:48:41.580+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:48:42.092+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:48:42.214+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:48:42.214+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:48:42.240+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:48:42.239+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:48:42.268+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.696 seconds
[2024-01-08T03:49:13.129+0000] {processor.py:161} INFO - Started process (PID=2887) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:49:13.132+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:49:13.133+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:49:13.133+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:49:13.644+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:49:13.669+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:49:13.668+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:49:13.697+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:49:13.696+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:49:13.718+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.594 seconds
[2024-01-08T03:49:44.472+0000] {processor.py:161} INFO - Started process (PID=2947) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:49:44.475+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:49:44.476+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:49:44.475+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:49:44.979+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:49:45.003+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:49:45.003+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:49:45.032+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:49:45.031+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:49:45.054+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.587 seconds
[2024-01-08T03:50:15.738+0000] {processor.py:161} INFO - Started process (PID=3007) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:50:15.740+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:50:15.742+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:50:15.741+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:50:16.351+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:50:16.377+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:50:16.377+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:50:16.408+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:50:16.408+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:50:16.432+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.700 seconds
[2024-01-08T03:50:46.508+0000] {processor.py:161} INFO - Started process (PID=3068) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:50:46.509+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:50:46.510+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:50:46.510+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:50:47.060+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:50:47.084+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:50:47.084+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:50:47.112+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:50:47.112+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:50:47.135+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.633 seconds
[2024-01-08T03:51:17.745+0000] {processor.py:161} INFO - Started process (PID=3128) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:51:17.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:51:17.749+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:51:17.749+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:51:18.338+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:51:18.362+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:51:18.362+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:51:18.393+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:51:18.393+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:51:18.418+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.679 seconds
[2024-01-08T03:51:20.409+0000] {processor.py:161} INFO - Started process (PID=3135) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:51:20.410+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:51:20.411+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:51:20.411+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:51:21.037+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:51:21.067+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:51:21.065+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:51:21.099+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:51:21.099+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:51:21.128+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.725 seconds
[2024-01-08T03:51:22.175+0000] {processor.py:161} INFO - Started process (PID=3150) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:51:22.176+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:51:22.177+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:51:22.177+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:51:22.182+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:51:22.181+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 133
    if
      ^
SyntaxError: invalid syntax
[2024-01-08T03:51:22.182+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:51:22.211+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.041 seconds
[2024-01-08T03:51:25.222+0000] {processor.py:161} INFO - Started process (PID=3151) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:51:25.224+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:51:25.225+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:51:25.225+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:51:25.233+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:51:25.232+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 134
    task_datalake.set_upstream(internal_task_depen_from_task_datalake)
    ^
IndentationError: expected an indented block
[2024-01-08T03:51:25.234+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:51:25.264+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.049 seconds
[2024-01-08T03:51:27.271+0000] {processor.py:161} INFO - Started process (PID=3152) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:51:27.272+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:51:27.273+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:51:27.273+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:51:27.805+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:51:27.832+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:51:27.831+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:51:27.859+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:51:27.858+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:51:27.886+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.620 seconds
[2024-01-08T03:51:29.317+0000] {processor.py:161} INFO - Started process (PID=3154) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:51:29.318+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:51:29.319+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:51:29.318+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:51:29.822+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:51:29.847+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:51:29.846+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:51:29.874+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:51:29.874+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:51:29.898+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.587 seconds
[2024-01-08T03:52:00.917+0000] {processor.py:161} INFO - Started process (PID=3215) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:52:00.920+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:52:00.921+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:52:00.921+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:52:01.455+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:52:01.479+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:52:01.478+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:52:01.506+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:52:01.505+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:52:01.528+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.617 seconds
[2024-01-08T03:52:32.209+0000] {processor.py:161} INFO - Started process (PID=3275) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:52:32.211+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:52:32.213+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:52:32.212+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:52:32.821+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:52:32.846+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:52:32.845+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:52:32.872+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:52:32.872+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:52:32.894+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.692 seconds
[2024-01-08T03:53:03.061+0000] {processor.py:161} INFO - Started process (PID=3336) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:53:03.062+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:53:03.063+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:53:03.063+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:53:03.592+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:53:03.623+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:53:03.622+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:53:03.650+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:53:03.650+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:53:03.672+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.617 seconds
[2024-01-08T03:53:34.002+0000] {processor.py:161} INFO - Started process (PID=3395) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:53:34.004+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:53:34.005+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:53:34.005+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:53:34.553+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:53:34.577+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:53:34.577+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:53:34.605+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:53:34.605+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:53:34.633+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.636 seconds
[2024-01-08T03:54:04.923+0000] {processor.py:161} INFO - Started process (PID=3456) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:54:04.924+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:54:04.925+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:54:04.925+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:54:05.431+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:54:05.456+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:54:05.456+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:54:05.483+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:54:05.483+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:54:05.509+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.590 seconds
[2024-01-08T03:54:36.081+0000] {processor.py:161} INFO - Started process (PID=3516) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:54:36.084+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:54:36.086+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:54:36.085+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:54:36.657+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:54:36.689+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:54:36.688+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:54:36.720+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:54:36.720+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:54:36.947+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.872 seconds
[2024-01-08T03:55:07.028+0000] {processor.py:161} INFO - Started process (PID=3578) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:55:07.030+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:55:07.032+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:55:07.031+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:55:07.530+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:55:07.555+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:55:07.554+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:55:07.783+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:55:07.783+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:55:07.804+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.781 seconds
[2024-01-08T03:55:38.531+0000] {processor.py:161} INFO - Started process (PID=3638) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:55:38.533+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:55:38.534+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:55:38.534+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:55:39.102+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:55:39.125+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:55:39.124+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:55:39.346+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:55:39.345+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:55:39.366+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.840 seconds
[2024-01-08T03:56:10.153+0000] {processor.py:161} INFO - Started process (PID=3702) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:56:10.154+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:56:10.155+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:56:10.155+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:56:10.713+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:56:10.738+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:56:10.737+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:56:10.978+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:56:10.978+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:56:11.009+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.862 seconds
[2024-01-08T03:56:41.112+0000] {processor.py:161} INFO - Started process (PID=3768) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:56:41.114+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:56:41.115+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:56:41.115+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:56:41.644+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:56:41.865+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:56:41.864+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:56:41.889+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:56:41.889+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:56:41.912+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.805 seconds
[2024-01-08T03:57:12.695+0000] {processor.py:161} INFO - Started process (PID=3829) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:57:12.696+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:57:12.697+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:57:12.697+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:57:13.271+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:57:13.503+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:57:13.503+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:57:13.527+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:57:13.527+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:57:13.548+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.859 seconds
[2024-01-08T03:57:44.541+0000] {processor.py:161} INFO - Started process (PID=3891) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:57:44.544+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:57:44.546+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:57:44.545+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:57:45.173+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:57:45.401+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:57:45.400+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:57:45.432+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:57:45.431+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:57:45.453+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.918 seconds
[2024-01-08T03:58:16.283+0000] {processor.py:161} INFO - Started process (PID=3955) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:58:16.285+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:58:16.286+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:58:16.286+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:58:17.143+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:58:17.171+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:58:17.170+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:58:17.208+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:58:17.208+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:58:17.232+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.954 seconds
[2024-01-08T03:58:48.202+0000] {processor.py:161} INFO - Started process (PID=4019) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:58:48.205+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:58:48.207+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:58:48.207+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:58:49.101+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:58:49.128+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:58:49.127+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:58:49.161+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:58:49.160+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:58:49.183+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.986 seconds
[2024-01-08T03:59:19.564+0000] {processor.py:161} INFO - Started process (PID=4081) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:59:19.566+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:59:19.567+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:59:19.566+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:59:20.280+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:59:20.303+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:59:20.302+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:59:20.327+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:59:20.327+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:59:20.346+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.787 seconds
[2024-01-08T03:59:50.558+0000] {processor.py:161} INFO - Started process (PID=4145) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:59:50.560+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T03:59:50.561+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:59:50.561+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:59:51.261+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T03:59:51.282+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:59:51.281+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T03:59:51.308+0000] {logging_mixin.py:188} INFO - [2024-01-08T03:59:51.307+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T03:59:51.330+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.777 seconds
[2024-01-08T04:00:21.481+0000] {processor.py:161} INFO - Started process (PID=4208) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:00:21.482+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:00:21.483+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:00:21.483+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:00:22.182+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:00:22.203+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:00:22.202+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:00:22.229+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:00:22.228+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:00:22.248+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.773 seconds
[2024-01-08T04:00:52.571+0000] {processor.py:161} INFO - Started process (PID=4268) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:00:52.574+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:00:52.575+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:00:52.575+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:00:53.093+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:00:53.309+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:00:53.308+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:00:53.332+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:00:53.332+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:00:53.352+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.785 seconds
[2024-01-08T04:01:23.663+0000] {processor.py:161} INFO - Started process (PID=4334) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:01:23.664+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:01:23.665+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:01:23.665+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:01:24.194+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:01:24.422+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:01:24.421+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:01:24.458+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:01:24.457+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:01:24.482+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.823 seconds
[2024-01-08T04:01:54.857+0000] {processor.py:161} INFO - Started process (PID=4394) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:01:54.860+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:01:54.861+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:01:54.860+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:01:55.673+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:01:55.696+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:01:55.696+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:01:55.720+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:01:55.720+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:01:55.745+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.893 seconds
[2024-01-08T04:02:04.086+0000] {processor.py:161} INFO - Started process (PID=4415) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:02:04.087+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:02:04.088+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:02:04.088+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:02:04.790+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:02:04.810+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:02:04.809+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:02:04.835+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:02:04.834+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:02:04.856+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.774 seconds
[2024-01-08T04:02:07.115+0000] {processor.py:161} INFO - Started process (PID=4417) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:02:07.116+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:02:07.117+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:02:07.117+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:02:07.874+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:02:07.895+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:02:07.894+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:02:07.918+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:02:07.918+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:02:07.948+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.838 seconds
[2024-01-08T04:02:38.325+0000] {processor.py:161} INFO - Started process (PID=4477) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:02:38.328+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:02:38.329+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:02:38.329+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:02:39.023+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:02:39.042+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:02:39.041+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:02:39.066+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:02:39.065+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:02:39.086+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.766 seconds
[2024-01-08T04:03:09.163+0000] {processor.py:161} INFO - Started process (PID=4537) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:03:09.164+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:03:09.165+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:03:09.165+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:03:09.857+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:03:09.877+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:03:09.876+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:03:09.901+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:03:09.901+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:03:09.923+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.765 seconds
[2024-01-08T04:03:15.861+0000] {processor.py:161} INFO - Started process (PID=4546) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:03:15.863+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:03:15.865+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:03:15.864+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:03:16.665+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:03:16.684+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:03:16.684+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:03:16.708+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:03:16.708+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:03:16.730+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.875 seconds
[2024-01-08T04:03:18.181+0000] {processor.py:161} INFO - Started process (PID=4555) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:03:18.182+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:03:18.183+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:03:18.183+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:03:18.934+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:03:18.954+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:03:18.953+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:03:18.977+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:03:18.976+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:03:19.000+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.824 seconds
[2024-01-08T04:03:37.048+0000] {processor.py:161} INFO - Started process (PID=4601) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:03:37.049+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:03:37.050+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:03:37.049+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:03:37.761+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:03:37.782+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:03:37.781+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:03:37.812+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:03:37.811+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:03:37.843+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.800 seconds
[2024-01-08T04:03:40.297+0000] {processor.py:161} INFO - Started process (PID=4603) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:03:40.299+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:03:40.300+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:03:40.299+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:03:41.020+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:03:41.018+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 134, in <module>
    internal_task_depen_from_task_datalake = [task_datalake for task_datalake in list_task_datalake if task_datalake["task_id"] == internal_task_dependency]
  File "/opt/airflow/dags/etl_to_datalake.py", line 134, in <listcomp>
    internal_task_depen_from_task_datalake = [task_datalake for task_datalake in list_task_datalake if task_datalake["task_id"] == internal_task_dependency]
TypeError: 'PythonOperator' object is not subscriptable
[2024-01-08T04:03:41.020+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:03:41.039+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.746 seconds
[2024-01-08T04:04:11.534+0000] {processor.py:161} INFO - Started process (PID=4663) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:04:11.537+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:04:11.538+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:04:11.538+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:04:12.246+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:04:12.245+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 134, in <module>
    internal_task_depen_from_task_datalake = [task_datalake for task_datalake in list_task_datalake if task_datalake["task_id"] == internal_task_dependency]
  File "/opt/airflow/dags/etl_to_datalake.py", line 134, in <listcomp>
    internal_task_depen_from_task_datalake = [task_datalake for task_datalake in list_task_datalake if task_datalake["task_id"] == internal_task_dependency]
TypeError: 'PythonOperator' object is not subscriptable
[2024-01-08T04:04:12.246+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:04:12.264+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.734 seconds
[2024-01-08T04:04:43.055+0000] {processor.py:161} INFO - Started process (PID=4723) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:04:43.056+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:04:43.057+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:04:43.057+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:04:43.770+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:04:43.769+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 134, in <module>
    internal_task_depen_from_task_datalake = [task_datalake for task_datalake in list_task_datalake if task_datalake["task_id"] == internal_task_dependency]
  File "/opt/airflow/dags/etl_to_datalake.py", line 134, in <listcomp>
    internal_task_depen_from_task_datalake = [task_datalake for task_datalake in list_task_datalake if task_datalake["task_id"] == internal_task_dependency]
TypeError: 'PythonOperator' object is not subscriptable
[2024-01-08T04:04:43.771+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:04:43.792+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.742 seconds
[2024-01-08T04:04:44.837+0000] {processor.py:161} INFO - Started process (PID=4725) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:04:44.838+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:04:44.839+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:04:44.838+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:04:44.843+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:04:44.842+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 134
    internal_task_depen_from_task_datalake = [task_datalake for task_datalake in list_task_datalake if task_datalake."task_id"] == internal_task_dependency]
                                                                                                                     ^
SyntaxError: invalid syntax
[2024-01-08T04:04:44.844+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:04:44.872+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.040 seconds
[2024-01-08T04:04:45.848+0000] {processor.py:161} INFO - Started process (PID=4726) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:04:45.851+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:04:45.852+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:04:45.852+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:04:45.857+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:04:45.856+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 134
    internal_task_depen_from_task_datalake = [task_datalake for task_datalake in list_task_datalake if task_datalake.task_id"] == internal_task_dependency]
                                                                                                                                                          ^
SyntaxError: EOL while scanning string literal
[2024-01-08T04:04:45.857+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:04:45.880+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.037 seconds
[2024-01-08T04:04:48.285+0000] {processor.py:161} INFO - Started process (PID=4733) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:04:48.286+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:04:48.287+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:04:48.287+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:04:49.025+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:04:49.023+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:04:49.025+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:04:49.045+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.764 seconds
[2024-01-08T04:05:19.112+0000] {processor.py:161} INFO - Started process (PID=4798) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:05:19.113+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:05:19.113+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:05:19.113+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:05:19.818+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:05:19.816+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:05:19.818+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:05:19.835+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.729 seconds
[2024-01-08T04:05:50.403+0000] {processor.py:161} INFO - Started process (PID=4860) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:05:50.406+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:05:50.407+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:05:50.407+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:05:51.335+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:05:51.334+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:05:51.336+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:05:51.356+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.959 seconds
[2024-01-08T04:06:21.673+0000] {processor.py:161} INFO - Started process (PID=4921) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:06:21.675+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:06:21.676+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:06:21.675+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:06:22.520+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:06:22.518+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:06:22.521+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:06:22.543+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.875 seconds
[2024-01-08T04:06:52.867+0000] {processor.py:161} INFO - Started process (PID=4982) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:06:52.868+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:06:52.869+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:06:52.868+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:06:53.598+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:06:53.597+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:06:53.598+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:06:53.617+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.756 seconds
[2024-01-08T04:07:23.734+0000] {processor.py:161} INFO - Started process (PID=5046) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:07:23.736+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:07:23.737+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:07:23.737+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:07:24.425+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:07:24.423+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:07:24.425+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:07:24.446+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.717 seconds
[2024-01-08T04:07:54.889+0000] {processor.py:161} INFO - Started process (PID=5112) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:07:54.891+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:07:54.892+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:07:54.892+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:07:55.624+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:07:55.623+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:07:55.625+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:07:55.642+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.758 seconds
[2024-01-08T04:08:26.353+0000] {processor.py:161} INFO - Started process (PID=5174) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:08:26.356+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:08:26.357+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:08:26.356+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:08:27.061+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:08:27.060+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:08:27.061+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:08:27.079+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.731 seconds
[2024-01-08T04:08:57.220+0000] {processor.py:161} INFO - Started process (PID=5237) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:08:57.221+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:08:57.222+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:08:57.222+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:08:57.925+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:08:57.923+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:08:57.925+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:08:57.942+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.727 seconds
[2024-01-08T04:09:28.645+0000] {processor.py:161} INFO - Started process (PID=5300) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:09:28.648+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:09:28.649+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:09:28.648+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:09:29.343+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:09:29.342+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:09:29.344+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:09:29.361+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.721 seconds
[2024-01-08T04:09:59.961+0000] {processor.py:161} INFO - Started process (PID=5360) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:09:59.964+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:09:59.965+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:09:59.965+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:10:00.671+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:10:00.669+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:10:00.671+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:10:00.694+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.739 seconds
[2024-01-08T04:10:30.910+0000] {processor.py:161} INFO - Started process (PID=5420) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:10:30.911+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:10:30.913+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:10:30.912+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:10:31.681+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:10:31.680+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:10:31.681+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:10:31.699+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.795 seconds
[2024-01-08T04:11:02.270+0000] {processor.py:161} INFO - Started process (PID=5482) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:11:02.272+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:11:02.273+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:11:02.273+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:11:02.957+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:11:02.956+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:11:02.957+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:11:02.975+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.710 seconds
[2024-01-08T04:11:33.864+0000] {processor.py:161} INFO - Started process (PID=5545) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:11:33.866+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:11:33.868+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:11:33.867+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:11:34.598+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:11:34.596+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:11:34.598+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:11:34.617+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.760 seconds
[2024-01-08T04:12:04.713+0000] {processor.py:161} INFO - Started process (PID=5605) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:12:04.714+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:12:04.715+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:12:04.714+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:12:05.445+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:12:05.444+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:12:05.446+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:12:05.464+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.756 seconds
[2024-01-08T04:12:35.689+0000] {processor.py:161} INFO - Started process (PID=5669) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:12:35.692+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:12:35.693+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:12:35.693+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:12:36.403+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:12:36.402+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:12:36.403+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:12:36.421+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.739 seconds
[2024-01-08T04:13:06.468+0000] {processor.py:161} INFO - Started process (PID=5729) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:13:06.470+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:13:06.471+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:13:06.471+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:13:07.155+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:13:07.154+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:13:07.155+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:13:07.175+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.713 seconds
[2024-01-08T04:13:37.654+0000] {processor.py:161} INFO - Started process (PID=5789) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:13:37.655+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:13:37.656+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:13:37.656+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:13:38.375+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:13:38.374+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:13:38.375+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:13:38.392+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.743 seconds
[2024-01-08T04:14:08.446+0000] {processor.py:161} INFO - Started process (PID=5854) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:14:08.448+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:14:08.449+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:14:08.449+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:14:09.203+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:14:09.202+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:14:09.204+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:14:09.221+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.781 seconds
[2024-01-08T04:14:39.632+0000] {processor.py:161} INFO - Started process (PID=5915) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:14:39.633+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:14:39.634+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:14:39.633+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:14:40.311+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:14:40.309+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:14:40.311+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:14:40.331+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.704 seconds
[2024-01-08T04:15:10.978+0000] {processor.py:161} INFO - Started process (PID=5976) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:15:10.981+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:15:10.982+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:15:10.981+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:15:11.674+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:15:11.673+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:15:11.674+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:15:11.693+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.721 seconds
[2024-01-08T04:15:41.938+0000] {processor.py:161} INFO - Started process (PID=6036) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:15:41.939+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:15:41.940+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:15:41.940+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:15:42.612+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:15:42.611+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:15:42.612+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:15:42.630+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.697 seconds
[2024-01-08T04:16:13.070+0000] {processor.py:161} INFO - Started process (PID=6096) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:16:13.072+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:16:13.074+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:16:13.073+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:16:13.784+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:16:13.782+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:16:13.784+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:16:13.806+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.742 seconds
[2024-01-08T04:16:44.502+0000] {processor.py:161} INFO - Started process (PID=6158) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:16:44.505+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:16:44.506+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:16:44.505+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:16:45.184+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:16:45.183+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:16:45.185+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:16:45.203+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.706 seconds
[2024-01-08T04:17:15.953+0000] {processor.py:161} INFO - Started process (PID=6223) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:17:15.956+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:17:15.957+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:17:15.956+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:17:16.668+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:17:16.667+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:17:16.668+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:17:16.688+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.740 seconds
[2024-01-08T04:17:47.125+0000] {processor.py:161} INFO - Started process (PID=6283) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:17:47.126+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:17:47.127+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:17:47.126+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:17:47.811+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:17:47.810+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:17:47.812+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:17:47.832+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.712 seconds
[2024-01-08T04:18:18.474+0000] {processor.py:161} INFO - Started process (PID=6343) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:18:18.476+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:18:18.477+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:18:18.477+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:18:19.168+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:18:19.166+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:18:19.168+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:18:19.186+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.717 seconds
[2024-01-08T04:18:49.511+0000] {processor.py:161} INFO - Started process (PID=6404) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:18:49.513+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:18:49.514+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:18:49.513+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:18:50.191+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:18:50.190+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:18:50.192+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:18:50.211+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.704 seconds
[2024-01-08T04:19:16.395+0000] {processor.py:161} INFO - Started process (PID=6460) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:19:16.397+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:19:16.398+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:19:16.398+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:19:16.402+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:19:16.401+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 138
    for
       ^
SyntaxError: invalid syntax
[2024-01-08T04:19:16.403+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:19:16.431+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.041 seconds
[2024-01-08T04:19:26.246+0000] {processor.py:161} INFO - Started process (PID=6474) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:19:26.247+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:19:26.248+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:19:26.247+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:19:26.252+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:19:26.251+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 138
    for task_datalake in list_task_datalake
                                           ^
SyntaxError: invalid syntax
[2024-01-08T04:19:26.253+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:19:26.279+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.039 seconds
[2024-01-08T04:19:28.265+0000] {processor.py:161} INFO - Started process (PID=6475) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:19:28.266+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:19:28.267+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:19:28.267+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:19:28.272+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:19:28.271+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 139
    
    ^
SyntaxError: unexpected EOF while parsing
[2024-01-08T04:19:28.272+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:19:28.297+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.036 seconds
[2024-01-08T04:19:58.484+0000] {processor.py:161} INFO - Started process (PID=6534) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:19:58.486+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:19:58.487+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:19:58.487+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:19:58.491+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:19:58.490+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 139
    
    ^
SyntaxError: unexpected EOF while parsing
[2024-01-08T04:19:58.492+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:19:58.517+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.038 seconds
[2024-01-08T04:20:28.788+0000] {processor.py:161} INFO - Started process (PID=6593) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:20:28.789+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:20:28.790+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:20:28.790+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:20:28.794+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:20:28.794+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 139
    
    ^
SyntaxError: unexpected EOF while parsing
[2024-01-08T04:20:28.795+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:20:28.818+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.035 seconds
[2024-01-08T04:20:51.518+0000] {processor.py:161} INFO - Started process (PID=6644) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:20:51.521+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:20:51.522+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:20:51.521+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:20:51.526+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:20:51.525+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 140
    dict_config = get_config_yaml(path_config_yaml)
                                                  ^
IndentationError: unindent does not match any outer indentation level
[2024-01-08T04:20:51.526+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:20:51.549+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.036 seconds
[2024-01-08T04:20:52.540+0000] {processor.py:161} INFO - Started process (PID=6645) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:20:52.541+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:20:52.542+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:20:52.542+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:20:53.221+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:20:53.220+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:20:53.222+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:20:53.240+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.705 seconds
[2024-01-08T04:21:23.413+0000] {processor.py:161} INFO - Started process (PID=6705) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:21:23.414+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:21:23.415+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:21:23.415+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:21:24.121+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:21:24.119+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:21:24.121+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:21:24.138+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.731 seconds
[2024-01-08T04:21:37.105+0000] {processor.py:161} INFO - Started process (PID=6730) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:21:37.107+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:21:37.108+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:21:37.108+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:21:37.113+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:21:37.112+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 140
    path_config_yaml = config_dir_path.joinpath(datalake_file).joinpath('config.yaml')
    ^
IndentationError: expected an indented block
[2024-01-08T04:21:37.113+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:21:37.143+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.042 seconds
[2024-01-08T04:21:40.711+0000] {processor.py:161} INFO - Started process (PID=6741) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:21:40.712+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:21:40.713+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:21:40.713+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:21:41.396+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:21:41.395+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:21:41.396+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:21:41.415+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.709 seconds
[2024-01-08T04:22:12.276+0000] {processor.py:161} INFO - Started process (PID=6804) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:22:12.279+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:22:12.280+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:22:12.279+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:22:12.981+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:22:12.979+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_a
[2024-01-08T04:22:12.982+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:22:12.999+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.728 seconds
[2024-01-08T04:22:39.362+0000] {processor.py:161} INFO - Started process (PID=6857) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:22:39.363+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:22:39.364+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:22:39.364+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:22:40.104+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:22:40.215+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:22:40.214+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:22:40.241+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:22:40.240+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:22:40.265+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.907 seconds
[2024-01-08T04:23:05.101+0000] {processor.py:161} INFO - Started process (PID=6909) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:23:05.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:23:05.104+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:23:05.104+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:23:05.830+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:23:05.829+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 116, in <module>
    list_task_datalake.append()
TypeError: append() takes exactly one argument (0 given)
[2024-01-08T04:23:05.830+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:23:05.849+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.752 seconds
[2024-01-08T04:23:06.380+0000] {processor.py:161} INFO - Started process (PID=6913) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:23:06.382+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:23:06.383+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:23:06.383+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:23:07.095+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:23:07.107+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:23:07.106+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:23:07.131+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:23:07.131+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:23:07.155+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.780 seconds
[2024-01-08T04:23:11.144+0000] {processor.py:161} INFO - Started process (PID=6925) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:23:11.145+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:23:11.146+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:23:11.145+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:23:11.850+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:23:11.874+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:23:11.873+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:23:11.898+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:23:11.898+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:23:11.922+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.784 seconds
[2024-01-08T04:23:14.125+0000] {processor.py:161} INFO - Started process (PID=6932) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:23:14.126+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:23:14.127+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:23:14.127+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:23:14.840+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:23:14.864+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:23:14.864+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:23:14.894+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:23:14.893+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:23:14.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.804 seconds
[2024-01-08T04:23:19.607+0000] {processor.py:161} INFO - Started process (PID=6947) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:23:19.608+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:23:19.609+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:23:19.608+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:23:19.614+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:23:19.613+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 119
    })
    ^
SyntaxError: invalid syntax
[2024-01-08T04:23:19.615+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:23:19.647+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.045 seconds
[2024-01-08T04:23:31.059+0000] {processor.py:161} INFO - Started process (PID=6965) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:23:31.060+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:23:31.061+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:23:31.061+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:23:31.066+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:23:31.065+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 119
    })
    ^
SyntaxError: invalid syntax
[2024-01-08T04:23:31.067+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:23:31.092+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.039 seconds
[2024-01-08T04:23:33.135+0000] {processor.py:161} INFO - Started process (PID=6966) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:23:33.136+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:23:33.138+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:23:33.137+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:23:33.143+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:23:33.142+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 119
    })
    ^
SyntaxError: invalid syntax
[2024-01-08T04:23:33.144+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:23:33.169+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.040 seconds
[2024-01-08T04:23:58.470+0000] {processor.py:161} INFO - Started process (PID=7023) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:23:58.472+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:23:58.473+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:23:58.473+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:23:59.155+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:23:59.154+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 118, in <module>
    "internal_task_dependencies": dict_config[""]
KeyError: ''
[2024-01-08T04:23:59.156+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:23:59.174+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.709 seconds
[2024-01-08T04:24:04.831+0000] {processor.py:161} INFO - Started process (PID=7033) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:24:04.832+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:24:04.833+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:24:04.832+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:24:05.625+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:24:05.645+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:24:05.644+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:24:05.671+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:24:05.671+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:24:05.693+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.867 seconds
[2024-01-08T04:24:35.734+0000] {processor.py:161} INFO - Started process (PID=7098) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:24:35.736+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:24:35.738+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:24:35.737+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:24:36.450+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:24:36.474+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:24:36.473+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:24:36.503+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:24:36.503+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:24:36.522+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.793 seconds
[2024-01-08T04:24:45.169+0000] {processor.py:161} INFO - Started process (PID=7116) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:24:45.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:24:45.171+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:24:45.171+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:24:45.175+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:24:45.174+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142
    
    ^
SyntaxError: unexpected EOF while parsing
[2024-01-08T04:24:45.175+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:24:45.201+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.036 seconds
[2024-01-08T04:25:01.502+0000] {processor.py:161} INFO - Started process (PID=7146) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:01.503+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:25:01.504+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:25:01.504+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:01.508+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:25:01.508+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142
    
    ^
SyntaxError: unexpected EOF while parsing
[2024-01-08T04:25:01.509+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:01.533+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.035 seconds
[2024-01-08T04:25:19.312+0000] {processor.py:161} INFO - Started process (PID=7190) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:19.315+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:25:19.317+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:25:19.316+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:19.322+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:25:19.321+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142
    
    ^
SyntaxError: unexpected EOF while parsing
[2024-01-08T04:25:19.322+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:19.351+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.043 seconds
[2024-01-08T04:25:22.337+0000] {processor.py:161} INFO - Started process (PID=7191) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:22.339+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:25:22.340+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:25:22.340+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:23.094+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:25:23.093+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <module>
    dict_task_datalake[""]
KeyError: ''
[2024-01-08T04:25:23.094+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:23.113+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.783 seconds
[2024-01-08T04:25:28.029+0000] {processor.py:161} INFO - Started process (PID=7206) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:28.030+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:25:28.031+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:25:28.031+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:28.784+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:28.804+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:25:28.803+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:25:28.828+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:25:28.828+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:25:28.852+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.828 seconds
[2024-01-08T04:25:29.885+0000] {processor.py:161} INFO - Started process (PID=7210) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:29.886+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:25:29.887+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:25:29.887+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:30.578+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:30.599+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:25:30.598+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:25:30.630+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:25:30.630+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:25:30.651+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.770 seconds
[2024-01-08T04:25:33.918+0000] {processor.py:161} INFO - Started process (PID=7212) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:33.919+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:25:33.919+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:25:33.919+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:34.610+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:34.631+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:25:34.630+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:25:34.656+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:25:34.655+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:25:34.682+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.770 seconds
[2024-01-08T04:25:36.953+0000] {processor.py:161} INFO - Started process (PID=7227) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:36.954+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:25:36.955+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:25:36.954+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:36.959+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:25:36.958+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142
    dict_task_datalake["task_datalake"].task_id ==
                                                  ^
SyntaxError: invalid syntax
[2024-01-08T04:25:36.960+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:36.985+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.038 seconds
[2024-01-08T04:25:49.459+0000] {processor.py:161} INFO - Started process (PID=7252) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:49.460+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:25:49.462+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:25:49.461+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:49.468+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:25:49.466+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142
    dict_task_datalake["internal_task_dependencies"].task_id ==
                                                               ^
SyntaxError: invalid syntax
[2024-01-08T04:25:49.468+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:49.498+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.044 seconds
[2024-01-08T04:25:54.253+0000] {processor.py:161} INFO - Started process (PID=7266) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:54.255+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:25:54.256+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:25:54.256+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:54.948+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:25:54.968+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:25:54.967+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:25:54.995+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:25:54.995+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:25:55.018+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.771 seconds
[2024-01-08T04:26:10.304+0000] {processor.py:161} INFO - Started process (PID=7291) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:10.305+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:26:10.306+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:26:10.306+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:10.310+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:26:10.309+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142
    dict_task_datalake["internal_task_dependencies"] =
                                                      ^
SyntaxError: invalid syntax
[2024-01-08T04:26:10.311+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:10.336+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.038 seconds
[2024-01-08T04:26:21.739+0000] {processor.py:161} INFO - Started process (PID=7320) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:21.741+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:26:21.742+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:26:21.741+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:22.493+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:26:22.492+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <module>
    dict_task_datalake["internal_task_dependencies"] = map(lambda x: x, )
TypeError: map() must have at least two arguments.
[2024-01-08T04:26:22.493+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:22.512+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.778 seconds
[2024-01-08T04:26:33.044+0000] {processor.py:161} INFO - Started process (PID=7337) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:33.047+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:26:33.048+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:26:33.048+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:33.725+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:33.746+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:26:33.745+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:26:33.773+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:26:33.772+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:26:33.796+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.757 seconds
[2024-01-08T04:26:44.489+0000] {processor.py:161} INFO - Started process (PID=7366) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:44.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:26:44.492+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:26:44.491+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:45.163+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:45.183+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:26:45.183+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:26:45.208+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:26:45.208+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:26:45.231+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.748 seconds
[2024-01-08T04:26:49.655+0000] {processor.py:161} INFO - Started process (PID=7372) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:49.656+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:26:49.657+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:26:49.657+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:50.390+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:50.410+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:26:50.409+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:26:50.435+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:26:50.434+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:26:50.458+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.807 seconds
[2024-01-08T04:26:52.197+0000] {processor.py:161} INFO - Started process (PID=7386) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:52.198+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:26:52.199+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:26:52.199+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:52.924+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:52.944+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:26:52.944+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:26:52.970+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:26:52.970+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:26:52.990+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.799 seconds
[2024-01-08T04:26:55.602+0000] {processor.py:161} INFO - Started process (PID=7395) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:55.603+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:26:55.604+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:26:55.604+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:56.396+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:56.423+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:26:56.422+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:26:56.452+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:26:56.451+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:26:56.474+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.878 seconds
[2024-01-08T04:26:57.625+0000] {processor.py:161} INFO - Started process (PID=7403) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:57.626+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:26:57.627+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:26:57.627+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:57.632+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:26:57.631+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142
    dict_task_datalake["internal_task_dependencies"] = map(lambda item: item[], list_dict_task_datalake)
                                                                             ^
SyntaxError: invalid syntax
[2024-01-08T04:26:57.632+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:57.656+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.036 seconds
[2024-01-08T04:26:59.647+0000] {processor.py:161} INFO - Started process (PID=7404) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:26:59.648+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:26:59.649+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:26:59.648+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:27:00.321+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:27:00.343+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:27:00.342+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:27:00.368+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:27:00.368+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:27:00.391+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.749 seconds
[2024-01-08T04:27:30.924+0000] {processor.py:161} INFO - Started process (PID=7464) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:27:30.927+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:27:30.928+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:27:30.928+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:27:31.592+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:27:31.612+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:27:31.611+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:27:31.637+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:27:31.637+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:27:31.658+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.740 seconds
[2024-01-08T04:28:01.900+0000] {processor.py:161} INFO - Started process (PID=7525) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:28:01.902+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:28:01.903+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:28:01.903+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:28:02.588+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:28:02.608+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:28:02.607+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:28:02.634+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:28:02.634+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:28:02.654+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.760 seconds
[2024-01-08T04:28:33.357+0000] {processor.py:161} INFO - Started process (PID=7585) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:28:33.360+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:28:33.361+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:28:33.360+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:28:34.056+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:28:34.076+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:28:34.075+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:28:34.099+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:28:34.099+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:28:34.122+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.770 seconds
[2024-01-08T04:28:49.210+0000] {processor.py:161} INFO - Started process (PID=7618) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:28:49.211+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:28:49.212+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:28:49.211+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:28:49.889+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:28:49.911+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:28:49.910+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:28:49.936+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:28:49.936+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:28:49.959+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.754 seconds
[2024-01-08T04:29:20.543+0000] {processor.py:161} INFO - Started process (PID=7679) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:29:20.545+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:29:20.547+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:29:20.546+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:29:21.266+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:29:21.287+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:29:21.286+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:29:21.312+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:29:21.311+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:29:21.333+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.797 seconds
[2024-01-08T04:29:52.212+0000] {processor.py:161} INFO - Started process (PID=7740) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:29:52.213+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:29:52.214+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:29:52.214+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:29:52.892+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:29:52.890+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <module>
    dict_task_datalake["task_datalake"] = map(lambda item: item[""], filter())
TypeError: filter expected 2 arguments, got 0
[2024-01-08T04:29:52.892+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:29:52.912+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.705 seconds
[2024-01-08T04:29:57.508+0000] {processor.py:161} INFO - Started process (PID=7761) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:29:57.509+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:29:57.510+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:29:57.509+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:29:57.514+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:29:57.513+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142
    dict_task_datalake["task_datalake"] = map(lambda item: item[""], filter(lambda ))
                                                                                   ^
SyntaxError: invalid syntax
[2024-01-08T04:29:57.514+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:29:57.542+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.039 seconds
[2024-01-08T04:30:01.564+0000] {processor.py:161} INFO - Started process (PID=7769) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:30:01.565+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:30:01.567+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:30:01.566+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:30:01.571+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:30:01.570+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142
    dict_task_datalake["task_datalake"] = map(lambda item: item[""], filter(lambda task_depen: ))
                                                                                               ^
SyntaxError: invalid syntax
[2024-01-08T04:30:01.572+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:30:01.595+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.035 seconds
[2024-01-08T04:30:03.604+0000] {processor.py:161} INFO - Started process (PID=7770) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:30:03.605+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:30:03.606+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:30:03.605+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:30:04.295+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:30:04.294+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <module>
    dict_task_datalake["task_datalake"] = map(lambda item: item[""], filter(lambda task_depen: task))
TypeError: filter expected 2 arguments, got 1
[2024-01-08T04:30:04.295+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:30:04.315+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.716 seconds
[2024-01-08T04:30:05.361+0000] {processor.py:161} INFO - Started process (PID=7772) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:30:05.362+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:30:05.363+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:30:05.362+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:30:06.043+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:30:06.042+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <module>
    dict_task_datalake["task_datalake"] = map(lambda item: item[""], filter(lambda task_depen: task_depen,))
TypeError: filter expected 2 arguments, got 1
[2024-01-08T04:30:06.043+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:30:06.063+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.707 seconds
[2024-01-08T04:30:07.657+0000] {processor.py:161} INFO - Started process (PID=7774) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:30:07.659+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:30:07.660+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:30:07.659+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:30:08.386+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:30:08.384+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <module>
    dict_task_datalake["task_datalake"] = map(lambda item: item[""], filter(lambda task_depen: task_depen, ))
TypeError: filter expected 2 arguments, got 1
[2024-01-08T04:30:08.387+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:30:08.409+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.758 seconds
[2024-01-08T04:30:19.684+0000] {processor.py:161} INFO - Started process (PID=7807) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:30:19.685+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:30:19.686+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:30:19.686+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:30:20.376+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:30:20.398+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:30:20.397+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:30:20.421+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:30:20.421+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:30:20.444+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.765 seconds
[2024-01-08T04:30:25.645+0000] {processor.py:161} INFO - Started process (PID=7823) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:30:25.647+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:30:25.648+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:30:25.648+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:30:26.360+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:30:26.359+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <module>
    dict_task_datalake["task_datalake"] = map(lambda item: item[""], filter(lambda task_depen: task_depen, dict_task_datalake[""]))
KeyError: ''
[2024-01-08T04:30:26.361+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:30:26.380+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.741 seconds
[2024-01-08T04:30:53.281+0000] {processor.py:161} INFO - Started process (PID=7871) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:30:53.283+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:30:53.283+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:30:53.283+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:30:53.971+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:30:53.969+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <module>
    dict_task_datalake["task_datalake"] = map(lambda item: item[""], filter(lambda task_depen: task_depen, dict_task_datalake["task_datalake"]))
TypeError: 'PythonOperator' object is not iterable
[2024-01-08T04:30:53.971+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:30:53.990+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.713 seconds
[2024-01-08T04:31:24.486+0000] {processor.py:161} INFO - Started process (PID=7932) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:31:24.489+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:31:24.490+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:31:24.489+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:31:25.209+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:31:25.207+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <module>
    dict_task_datalake["task_datalake"] = map(lambda item: item[""], filter(lambda task_depen: task_depen, dict_task_datalake["task_datalake"]))
TypeError: 'PythonOperator' object is not iterable
[2024-01-08T04:31:25.209+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:31:25.227+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.746 seconds
[2024-01-08T04:31:55.344+0000] {processor.py:161} INFO - Started process (PID=7997) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:31:55.345+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:31:55.347+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:31:55.346+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:31:56.069+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:31:56.068+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <module>
    dict_task_datalake["task_datalake"] = map(lambda item: item[""], filter(lambda task_depen: task_depen, dict_task_datalake["task_datalake"]))
TypeError: 'PythonOperator' object is not iterable
[2024-01-08T04:31:56.070+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:31:56.088+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.749 seconds
[2024-01-08T04:32:11.172+0000] {processor.py:161} INFO - Started process (PID=8019) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:32:11.173+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:32:11.174+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:32:11.174+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:32:11.936+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:32:11.934+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <module>
    dict_task_datalake["task_datalake"] = map(lambda item: item.task_, filter(lambda task_depen: task_depen, dict_task_datalake["task_datalake"]))
TypeError: 'PythonOperator' object is not iterable
[2024-01-08T04:32:11.936+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:32:11.954+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.787 seconds
[2024-01-08T04:32:12.963+0000] {processor.py:161} INFO - Started process (PID=8027) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:32:12.964+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:32:12.965+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:32:12.964+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:32:13.702+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:32:13.700+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <module>
    dict_task_datalake["task_datalake"] = map(lambda item: item.task_id, filter(lambda task_depen: task_depen, dict_task_datalake["task_datalake"]))
TypeError: 'PythonOperator' object is not iterable
[2024-01-08T04:32:13.702+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:32:13.720+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.762 seconds
[2024-01-08T04:32:17.103+0000] {processor.py:161} INFO - Started process (PID=8040) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:32:17.104+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:32:17.105+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:32:17.105+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:32:17.841+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:32:17.840+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <module>
    dict_task_datalake["task_datalake"].map(lambda item: item.task_id, filter(lambda task_depen: task_depen, dict_task_datalake["task_datalake"]))
AttributeError: 'PythonOperator' object has no attribute 'map'
[2024-01-08T04:32:17.842+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:32:17.861+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.763 seconds
[2024-01-08T04:32:20.295+0000] {processor.py:161} INFO - Started process (PID=8052) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:32:20.296+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:32:20.297+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:32:20.297+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:32:21.029+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:32:21.027+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <module>
    dict_task_datalake["task_datalake"].set_upstream*map(lambda item: item.task_id, filter(lambda task_depen: task_depen, dict_task_datalake["task_datalake"]))
TypeError: 'PythonOperator' object is not iterable
[2024-01-08T04:32:21.030+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:32:21.055+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.765 seconds
[2024-01-08T04:32:23.214+0000] {processor.py:161} INFO - Started process (PID=8059) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:32:23.216+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:32:23.217+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:32:23.217+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:32:23.223+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:32:23.222+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 143
    map(lambda item: item.task_id, filter(lambda task_depen: task_depen, dict_task_datalake["task_datalake"]))
                                                                                                             ^
SyntaxError: unexpected EOF while parsing
[2024-01-08T04:32:23.224+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:32:23.249+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.041 seconds
[2024-01-08T04:32:26.625+0000] {processor.py:161} INFO - Started process (PID=8066) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:32:26.627+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:32:26.628+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:32:26.628+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:32:27.379+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:32:27.377+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 143, in <module>
    map(lambda item: item.task_id, filter(lambda task_depen: task_depen, dict_task_datalake["task_datalake"]))
TypeError: 'PythonOperator' object is not iterable
[2024-01-08T04:32:27.379+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:32:27.398+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.778 seconds
[2024-01-08T04:32:58.105+0000] {processor.py:161} INFO - Started process (PID=8129) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:32:58.107+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:32:58.108+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:32:58.108+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:32:58.850+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:32:58.849+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 143, in <module>
    map(lambda item: item.task_id, filter(lambda task_depen: task_depen, dict_task_datalake["task_datalake"]))
TypeError: 'PythonOperator' object is not iterable
[2024-01-08T04:32:58.850+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:32:58.871+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.771 seconds
[2024-01-08T04:33:04.347+0000] {processor.py:161} INFO - Started process (PID=8149) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:33:04.348+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:33:04.349+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:33:04.349+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:33:05.037+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:33:05.036+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 143, in <module>
    map(lambda item: item.task_id, filter(lambda task_depen: task_depen, dict_task_datalake["task_datalake"].task))
AttributeError: 'PythonOperator' object has no attribute 'task'
[2024-01-08T04:33:05.038+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:33:05.057+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.715 seconds
[2024-01-08T04:33:06.099+0000] {processor.py:161} INFO - Started process (PID=8151) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:33:06.101+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:33:06.102+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:33:06.101+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:33:06.106+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:33:06.105+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 143
    map(lambda item: item.task_id, filter(lambda task_depen: task_depen, dict_task_datalake["task_datalake"].task_id in ))
                                                                                                                        ^
SyntaxError: invalid syntax
[2024-01-08T04:33:06.107+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:33:06.137+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.043 seconds
[2024-01-08T04:33:10.126+0000] {processor.py:161} INFO - Started process (PID=8152) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:33:10.127+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:33:10.128+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:33:10.128+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:33:10.839+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:33:10.838+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 143, in <module>
    map(lambda item: item.task_id, filter(lambda task_depen: task_depen, dict_task_datalake["task_datalake"].task_id in dict_task_datalake))
TypeError: 'bool' object is not iterable
[2024-01-08T04:33:10.839+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:33:10.857+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.735 seconds
[2024-01-08T04:33:11.899+0000] {processor.py:161} INFO - Started process (PID=8154) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:33:11.900+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:33:11.901+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:33:11.900+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:33:12.601+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:33:12.599+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 143, in <module>
    map(lambda item: item.task_id, filter(lambda task_depen: task_depen, dict_task_datalake["task_datalake"].task_id in dict_task_datalake[""]))
KeyError: ''
[2024-01-08T04:33:12.601+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:33:12.620+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.726 seconds
[2024-01-08T04:33:17.441+0000] {processor.py:161} INFO - Started process (PID=8169) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:33:17.442+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:33:17.443+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:33:17.442+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:33:18.137+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:33:18.136+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <module>
    dict_task_datalake["task_datalake"].set_upstream(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    task_object.update_relative(self, not upstream, edge_modifier=edge_modifier)
AttributeError: 'map' object has no attribute 'update_relative'
[2024-01-08T04:33:18.138+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:33:18.162+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.726 seconds
[2024-01-08T04:33:49.173+0000] {processor.py:161} INFO - Started process (PID=8229) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:33:49.176+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:33:49.178+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:33:49.177+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:33:49.982+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:33:49.980+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <module>
    dict_task_datalake["task_datalake"].set_upstream(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    task_object.update_relative(self, not upstream, edge_modifier=edge_modifier)
AttributeError: 'map' object has no attribute 'update_relative'
[2024-01-08T04:33:49.982+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:33:50.008+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.840 seconds
[2024-01-08T04:34:03.781+0000] {processor.py:161} INFO - Started process (PID=8276) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:34:03.782+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:34:03.783+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:34:03.783+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:34:03.788+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:34:03.787+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142
    dict_task_datalake["task_datalake"].set_upstream(
    ^
IndentationError: unexpected indent
[2024-01-08T04:34:03.789+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:34:03.816+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.040 seconds
[2024-01-08T04:34:05.831+0000] {processor.py:161} INFO - Started process (PID=8277) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:34:05.832+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:34:05.833+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:34:05.833+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:34:05.839+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:34:05.838+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142
    dict_task_datalake["task_datalake"].set_upstream(
    ^
IndentationError: unexpected indent
[2024-01-08T04:34:05.839+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:34:05.862+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.036 seconds
[2024-01-08T04:34:06.868+0000] {processor.py:161} INFO - Started process (PID=8278) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:34:06.869+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:34:06.870+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:34:06.869+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:34:07.621+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:34:07.619+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <module>
    dict_task_datalake["task_datalake"].set_upstream(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    task_object.update_relative(self, not upstream, edge_modifier=edge_modifier)
AttributeError: 'map' object has no attribute 'update_relative'
[2024-01-08T04:34:07.621+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:34:07.643+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.781 seconds
[2024-01-08T04:34:11.710+0000] {processor.py:161} INFO - Started process (PID=8280) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:34:11.711+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:34:11.712+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:34:11.711+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:34:12.408+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:34:12.407+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 144, in <module>
    dict_task_datalake["task_datalake"].set_upstream(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    task_object.update_relative(self, not upstream, edge_modifier=edge_modifier)
AttributeError: 'map' object has no attribute 'update_relative'
[2024-01-08T04:34:12.409+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:34:12.427+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.723 seconds
[2024-01-08T04:34:12.934+0000] {processor.py:161} INFO - Started process (PID=8282) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:34:12.935+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:34:12.936+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:34:12.936+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:34:13.636+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:34:13.635+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 143, in <module>
    dict_task_datalake["task_datalake"].set_upstream(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    task_object.update_relative(self, not upstream, edge_modifier=edge_modifier)
AttributeError: 'map' object has no attribute 'update_relative'
[2024-01-08T04:34:13.637+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:34:13.656+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.727 seconds
[2024-01-08T04:34:14.665+0000] {processor.py:161} INFO - Started process (PID=8288) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:34:14.666+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:34:14.667+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:34:14.667+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:34:14.671+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:34:14.670+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 143
    dict_task_datalake["task_datalake"].set_upstream(
                                                    ^
IndentationError: unindent does not match any outer indentation level
[2024-01-08T04:34:14.672+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:34:14.698+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.039 seconds
[2024-01-08T04:34:22.862+0000] {processor.py:161} INFO - Started process (PID=8314) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:34:22.863+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:34:22.864+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:34:22.864+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:34:23.552+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:34:23.550+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <module>
    internal_task_depen_from_task_datalake = [task_datalake for task_datalake in list_dict_task_datalake if task_datalake.task_id == internal_task_dependency]
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <listcomp>
    internal_task_depen_from_task_datalake = [task_datalake for task_datalake in list_dict_task_datalake if task_datalake.task_id == internal_task_dependency]
AttributeError: 'dict' object has no attribute 'task_id'
[2024-01-08T04:34:23.552+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:34:23.571+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.714 seconds
[2024-01-08T04:34:53.634+0000] {processor.py:161} INFO - Started process (PID=8372) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:34:53.637+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:34:53.638+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:34:53.638+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:34:54.347+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:34:54.346+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <module>
    internal_task_depen_from_task_datalake = [task_datalake for task_datalake in list_dict_task_datalake if task_datalake.task_id == internal_task_dependency]
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <listcomp>
    internal_task_depen_from_task_datalake = [task_datalake for task_datalake in list_dict_task_datalake if task_datalake.task_id == internal_task_dependency]
AttributeError: 'dict' object has no attribute 'task_id'
[2024-01-08T04:34:54.348+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:34:54.368+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.739 seconds
[2024-01-08T04:35:00.075+0000] {processor.py:161} INFO - Started process (PID=8394) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:35:00.076+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:35:00.077+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:35:00.077+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:35:00.788+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:35:00.787+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <module>
    internal_task_depen_from_task_datalake = [task_datalake for task_datalake in list_dict_task_datalake if task_datalake.task_id in internal_task_dependency]
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <listcomp>
    internal_task_depen_from_task_datalake = [task_datalake for task_datalake in list_dict_task_datalake if task_datalake.task_id in internal_task_dependency]
AttributeError: 'dict' object has no attribute 'task_id'
[2024-01-08T04:35:00.788+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:35:00.808+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.737 seconds
[2024-01-08T04:35:09.452+0000] {processor.py:161} INFO - Started process (PID=8407) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:35:09.453+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:35:09.454+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:35:09.453+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:35:09.458+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:35:09.457+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142
    internal_task_depen_from_task_datalake = [task_datalake for task_datalake in list_dict_task_datalake if task_datalake.task_id in dict_task_datalake[]]
                                                                                                                                                        ^
SyntaxError: invalid syntax
[2024-01-08T04:35:09.458+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:35:09.481+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.034 seconds
[2024-01-08T04:35:10.477+0000] {processor.py:161} INFO - Started process (PID=8408) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:35:10.478+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:35:10.479+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:35:10.478+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:35:11.167+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:35:11.166+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <module>
    internal_task_depen_from_task_datalake = [task_datalake for task_datalake in list_dict_task_datalake if task_datalake.task_id in dict_task_datalake["internal_task_dependencies"]]
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <listcomp>
    internal_task_depen_from_task_datalake = [task_datalake for task_datalake in list_dict_task_datalake if task_datalake.task_id in dict_task_datalake["internal_task_dependencies"]]
AttributeError: 'dict' object has no attribute 'task_id'
[2024-01-08T04:35:11.168+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:35:11.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.715 seconds
[2024-01-08T04:35:36.946+0000] {processor.py:161} INFO - Started process (PID=8468) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:35:36.949+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:35:36.950+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:35:36.949+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:35:37.659+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:35:37.657+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 143, in <module>
    dict_task_datalake["task_datalake"].set_upstream(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    task_object.update_relative(self, not upstream, edge_modifier=edge_modifier)
AttributeError: 'map' object has no attribute 'update_relative'
[2024-01-08T04:35:37.659+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:35:37.678+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.737 seconds
[2024-01-08T04:35:39.727+0000] {processor.py:161} INFO - Started process (PID=8470) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:35:39.728+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:35:39.729+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:35:39.729+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:35:40.507+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:35:40.505+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 143, in <module>
    dict_task_datalake["task_datalake"].set_upstream(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    task_object.update_relative(self, not upstream, edge_modifier=edge_modifier)
AttributeError: 'map' object has no attribute 'update_relative'
[2024-01-08T04:35:40.508+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:35:40.537+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.815 seconds
[2024-01-08T04:35:43.621+0000] {processor.py:161} INFO - Started process (PID=8472) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:35:43.622+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:35:43.623+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:35:43.623+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:35:44.319+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:35:44.317+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <module>
    internal_task_depen_from_task_datalake = [dict_task_datalake["task_datalake"] for dict_task_datalake in list_dict_task_datalake if task_datalake.task_id in dict_task_datalake["internal_task_dependencies"]]
  File "/opt/airflow/dags/etl_to_datalake.py", line 142, in <listcomp>
    internal_task_depen_from_task_datalake = [dict_task_datalake["task_datalake"] for dict_task_datalake in list_dict_task_datalake if task_datalake.task_id in dict_task_datalake["internal_task_dependencies"]]
KeyError: ''
[2024-01-08T04:35:44.319+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:35:44.338+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.722 seconds
[2024-01-08T04:36:15.221+0000] {processor.py:161} INFO - Started process (PID=8532) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:36:15.224+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:36:15.225+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:36:15.225+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:36:15.740+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:36:15.739+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 143, in <module>
    dict_task_datalake["task_datalake"].set_upstream(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    task_object.update_relative(self, not upstream, edge_modifier=edge_modifier)
AttributeError: 'map' object has no attribute 'update_relative'
[2024-01-08T04:36:15.741+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:36:15.763+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.547 seconds
[2024-01-08T04:36:42.565+0000] {processor.py:161} INFO - Started process (PID=8592) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:36:42.567+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:36:42.568+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:36:42.568+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:36:42.573+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:36:42.572+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 143
    d`ict_task_datalake["task_datalake"].set_upstream(
     ^
SyntaxError: invalid syntax
[2024-01-08T04:36:42.573+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:36:42.596+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.036 seconds
[2024-01-08T04:36:44.640+0000] {processor.py:161} INFO - Started process (PID=8593) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:36:44.641+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:36:44.642+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:36:44.642+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:36:45.163+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:36:45.281+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:36:45.280+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:36:45.310+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:36:45.309+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:36:45.341+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.707 seconds
[2024-01-08T04:36:48.694+0000] {processor.py:161} INFO - Started process (PID=8600) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:36:48.695+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:36:48.696+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:36:48.696+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:36:49.351+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:36:49.349+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 146, in <module>
    map()
TypeError: map() must have at least two arguments.
[2024-01-08T04:36:49.352+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:36:49.380+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.691 seconds
[2024-01-08T04:36:51.608+0000] {processor.py:161} INFO - Started process (PID=8610) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:36:51.609+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:36:51.610+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:36:51.610+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:36:51.615+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:36:51.614+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 146
    map(lambda x)
                ^
SyntaxError: invalid syntax
[2024-01-08T04:36:51.615+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:36:51.641+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.038 seconds
[2024-01-08T04:36:54.633+0000] {processor.py:161} INFO - Started process (PID=8611) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:36:54.634+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:36:54.636+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:36:54.635+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:36:55.271+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:36:55.269+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 146, in <module>
    map(lambda x: x.set_upstream)
TypeError: map() must have at least two arguments.
[2024-01-08T04:36:55.272+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:36:55.296+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.669 seconds
[2024-01-08T04:36:56.296+0000] {processor.py:161} INFO - Started process (PID=8622) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:36:56.298+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:36:56.299+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:36:56.299+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:36:56.881+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:36:56.879+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 146, in <module>
    map(lambda x: x.set_upstream())
TypeError: map() must have at least two arguments.
[2024-01-08T04:36:56.881+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:36:56.901+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.611 seconds
[2024-01-08T04:37:12.485+0000] {processor.py:161} INFO - Started process (PID=8661) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:12.486+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:37:12.487+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:12.487+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:12.997+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:13.013+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:13.012+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:37:13.049+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:13.049+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:37:13.076+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.595 seconds
[2024-01-08T04:37:17.827+0000] {processor.py:161} INFO - Started process (PID=8665) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:17.829+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:37:17.830+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:17.830+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:18.447+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:18.472+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:18.472+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:37:18.501+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:18.501+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:37:18.525+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.703 seconds
[2024-01-08T04:37:21.949+0000] {processor.py:161} INFO - Started process (PID=8678) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:21.950+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:37:21.951+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:21.950+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:22.475+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:22.474+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 146, in <module>
    dict_task_datalake["task_datalake"].set_upstream()
TypeError: set_upstream() missing 1 required positional argument: 'task_or_task_list'
[2024-01-08T04:37:22.476+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:22.499+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.555 seconds
[2024-01-08T04:37:23.989+0000] {processor.py:161} INFO - Started process (PID=8680) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:23.990+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:37:23.991+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:23.990+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:24.512+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:24.510+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 146, in <module>
    dict_task_datalake["task_datalake"].set_upstream(map)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    task_object.update_relative(self, not upstream, edge_modifier=edge_modifier)
AttributeError: type object 'map' has no attribute 'update_relative'
[2024-01-08T04:37:24.512+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:24.541+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.557 seconds
[2024-01-08T04:37:27.002+0000] {processor.py:161} INFO - Started process (PID=8688) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:27.003+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:37:27.004+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:27.004+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:27.624+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:27.622+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 146, in <module>
    dict_task_datalake["task_datalake"].set_upstream(map())
TypeError: map() must have at least two arguments.
[2024-01-08T04:37:27.624+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:27.646+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.649 seconds
[2024-01-08T04:37:29.658+0000] {processor.py:161} INFO - Started process (PID=8708) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:29.660+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:37:29.661+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:29.661+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:29.668+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:29.666+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 146
    dict_task_datalake["task_datalake"].set_upstream(map(lambda))
                                                               ^
SyntaxError: invalid syntax
[2024-01-08T04:37:29.668+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:29.706+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.054 seconds
[2024-01-08T04:37:33.941+0000] {processor.py:161} INFO - Started process (PID=8722) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:33.942+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:37:33.943+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:33.943+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:33.949+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:33.948+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 146
    dict_task_datalake["task_datalake"].set_upstream(map(lambdax: x, ))
                                                                ^
SyntaxError: invalid syntax
[2024-01-08T04:37:33.949+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:33.974+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.038 seconds
[2024-01-08T04:37:40.416+0000] {processor.py:161} INFO - Started process (PID=8731) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:40.417+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:37:40.418+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:40.418+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:40.949+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:40.948+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 146, in <module>
    dict_task_datalake["task_datalake"].set_upstream([internal_task_depen_from_task_datalake])
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 270, in set_upstream
    self._set_relatives(task_or_task_list, upstream=True, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    task_object.update_relative(self, not upstream, edge_modifier=edge_modifier)
AttributeError: 'list' object has no attribute 'update_relative'
[2024-01-08T04:37:40.950+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:40.973+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.562 seconds
[2024-01-08T04:37:42.011+0000] {processor.py:161} INFO - Started process (PID=8733) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:42.012+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:37:42.013+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:42.012+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:42.017+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:42.016+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 146
    dict_task_datalake["task_datalake"].set_upstream([for internal_task_depen_from_task_datalake])
                                                      ^
SyntaxError: invalid syntax
[2024-01-08T04:37:42.017+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:42.041+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.036 seconds
[2024-01-08T04:37:50.358+0000] {processor.py:161} INFO - Started process (PID=8739) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:50.360+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:37:50.361+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:50.361+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:50.367+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:50.365+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 146
    dict_task_datalake["task_datalake"].set_upstream([for internal_task_depen_from_task_datalake])
                                                      ^
SyntaxError: invalid syntax
[2024-01-08T04:37:50.367+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:50.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.048 seconds
[2024-01-08T04:37:53.087+0000] {processor.py:161} INFO - Started process (PID=8748) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:53.088+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:37:53.089+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:53.089+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:53.093+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:53.092+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 146
    dict_task_datalake["task_datalake"].set_upstream([for list_internal_task_depen_from_task_datalake])
                                                      ^
SyntaxError: invalid syntax
[2024-01-08T04:37:53.094+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:53.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.035 seconds
[2024-01-08T04:37:59.458+0000] {processor.py:161} INFO - Started process (PID=8765) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:59.459+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:37:59.460+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:59.460+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:59.466+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:37:59.465+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 839, in exec_module
  File "<frozen importlib._bootstrap_external>", line 976, in get_code
  File "<frozen importlib._bootstrap_external>", line 906, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 146
    dict_task_datalake["task_datalake"].set_upstream([for internal_task_depen_from_task_datalake in list_internal_task_depen_from_task_datalake])
                                                      ^
SyntaxError: invalid syntax
[2024-01-08T04:37:59.467+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:37:59.500+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.048 seconds
[2024-01-08T04:38:01.649+0000] {processor.py:161} INFO - Started process (PID=8782) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:38:01.650+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:38:01.651+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:38:01.651+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:38:02.180+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:38:02.179+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_b
[2024-01-08T04:38:02.180+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:38:02.202+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.561 seconds
[2024-01-08T04:38:05.656+0000] {processor.py:161} INFO - Started process (PID=8790) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:38:05.657+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:38:05.658+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:38:05.658+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:38:06.212+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:38:06.211+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_b
[2024-01-08T04:38:06.213+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:38:06.237+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.586 seconds
[2024-01-08T04:38:11.358+0000] {processor.py:161} INFO - Started process (PID=8800) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:38:11.359+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:38:11.360+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:38:11.360+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:38:11.891+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:38:11.890+0000] {dagbag.py:445} ERROR - Failed to bag_dag: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 441, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 460, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 468, in _bag_dag
    check_cycle(dag)  # throws if a task cycle is found
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 79, in check_cycle
    child_to_check = _check_adjacent_tasks(current_task_id, task)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/dag_cycle_tester.py", line 65, in _check_adjacent_tasks
    raise AirflowDagCycleException(msg)
airflow.exceptions.AirflowDagCycleException: Cycle detected in DAG: etl_to_datalake. Faulty task: table_source_b
[2024-01-08T04:38:11.892+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:38:11.914+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.560 seconds
[2024-01-08T04:38:37.653+0000] {processor.py:161} INFO - Started process (PID=8859) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:38:37.656+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:38:37.657+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:38:37.656+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:38:38.173+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:38:38.197+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:38:38.196+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:38:38.223+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:38:38.223+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:38:38.247+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.598 seconds
[2024-01-08T04:39:08.380+0000] {processor.py:161} INFO - Started process (PID=8920) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:39:08.381+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:39:08.382+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:39:08.381+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:39:08.894+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:39:08.921+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:39:08.920+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:39:08.948+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:39:08.948+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:39:08.969+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.594 seconds
[2024-01-08T04:39:39.639+0000] {processor.py:161} INFO - Started process (PID=8980) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:39:39.642+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:39:39.643+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:39:39.643+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:39:40.152+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:39:40.176+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:39:40.176+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:39:40.203+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:39:40.202+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:39:40.227+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.592 seconds
[2024-01-08T04:40:10.463+0000] {processor.py:161} INFO - Started process (PID=9040) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:40:10.465+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:40:10.466+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:40:10.466+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:40:11.264+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:40:11.303+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:40:11.302+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:40:11.345+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:40:11.345+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2023-12-26T00:00:00+00:00, run_after=2023-12-27T00:00:00+00:00
[2024-01-08T04:40:11.375+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.921 seconds
[2024-01-08T04:40:15.778+0000] {processor.py:161} INFO - Started process (PID=9042) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:40:15.781+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:40:15.782+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:40:15.782+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:40:16.433+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:40:16.613+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:40:16.612+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:40:16.649+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:40:16.649+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-12-26T00:00:00+00:00, run_after=2024-12-27T00:00:00+00:00
[2024-01-08T04:40:16.685+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.914 seconds
[2024-01-08T04:40:20.591+0000] {processor.py:161} INFO - Started process (PID=9046) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:40:20.592+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:40:20.593+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:40:20.592+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:40:21.105+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:40:21.119+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:40:21.118+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:40:21.147+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:40:21.146+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-26T00:00:00+00:00, run_after=2024-01-27T00:00:00+00:00
[2024-01-08T04:40:21.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.584 seconds
[2024-01-08T04:40:26.231+0000] {processor.py:161} INFO - Started process (PID=9059) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:40:26.234+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:40:26.237+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:40:26.236+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:40:27.048+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:40:27.076+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:40:27.074+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:40:27.140+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:40:27.140+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:40:27.186+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.970 seconds
[2024-01-08T04:40:36.112+0000] {processor.py:161} INFO - Started process (PID=9097) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:40:36.113+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:40:36.114+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:40:36.114+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:40:36.708+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:40:36.703+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 90, in <module>
    with DAG(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 525, in __init__
    date = timezone.parse(date)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timezone.py", line 207, in parse
    return pendulum.parse(string, tz=timezone or TIMEZONE, strict=strict)  # type: ignore
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parser.py", line 29, in parse
    return _parse(text, **options)
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parser.py", line 45, in _parse
    parsed = base_parse(text, **options)
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parsing/__init__.py", line 74, in parse
    return _normalize(_parse(text, **_options), **_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parsing/__init__.py", line 115, in _parse
    return _parse_iso8601_interval(text)
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parsing/__init__.py", line 215, in _parse_iso8601_interval
    if "/" not in text:
TypeError: argument of type 'datetime.timedelta' is not iterable
[2024-01-08T04:40:36.708+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:40:36.732+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.625 seconds
[2024-01-08T04:41:06.929+0000] {processor.py:161} INFO - Started process (PID=9158) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:41:06.931+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:41:06.933+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:41:06.932+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:41:07.432+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:41:07.429+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 90, in <module>
    with DAG(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 525, in __init__
    date = timezone.parse(date)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timezone.py", line 207, in parse
    return pendulum.parse(string, tz=timezone or TIMEZONE, strict=strict)  # type: ignore
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parser.py", line 29, in parse
    return _parse(text, **options)
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parser.py", line 45, in _parse
    parsed = base_parse(text, **options)
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parsing/__init__.py", line 74, in parse
    return _normalize(_parse(text, **_options), **_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parsing/__init__.py", line 115, in _parse
    return _parse_iso8601_interval(text)
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parsing/__init__.py", line 215, in _parse_iso8601_interval
    if "/" not in text:
TypeError: argument of type 'datetime.timedelta' is not iterable
[2024-01-08T04:41:07.432+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:41:07.455+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.532 seconds
[2024-01-08T04:41:38.081+0000] {processor.py:161} INFO - Started process (PID=9216) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:41:38.082+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:41:38.083+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:41:38.083+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:41:38.585+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:41:38.582+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 90, in <module>
    with DAG(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 525, in __init__
    date = timezone.parse(date)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timezone.py", line 207, in parse
    return pendulum.parse(string, tz=timezone or TIMEZONE, strict=strict)  # type: ignore
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parser.py", line 29, in parse
    return _parse(text, **options)
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parser.py", line 45, in _parse
    parsed = base_parse(text, **options)
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parsing/__init__.py", line 74, in parse
    return _normalize(_parse(text, **_options), **_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parsing/__init__.py", line 115, in _parse
    return _parse_iso8601_interval(text)
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parsing/__init__.py", line 215, in _parse_iso8601_interval
    if "/" not in text:
TypeError: argument of type 'datetime.timedelta' is not iterable
[2024-01-08T04:41:38.585+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:41:38.606+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.530 seconds
[2024-01-08T04:42:09.349+0000] {processor.py:161} INFO - Started process (PID=9276) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:42:09.352+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:42:09.353+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:42:09.352+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:42:09.849+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:42:09.847+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 90, in <module>
    with DAG(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 525, in __init__
    date = timezone.parse(date)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timezone.py", line 207, in parse
    return pendulum.parse(string, tz=timezone or TIMEZONE, strict=strict)  # type: ignore
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parser.py", line 29, in parse
    return _parse(text, **options)
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parser.py", line 45, in _parse
    parsed = base_parse(text, **options)
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parsing/__init__.py", line 74, in parse
    return _normalize(_parse(text, **_options), **_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parsing/__init__.py", line 115, in _parse
    return _parse_iso8601_interval(text)
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parsing/__init__.py", line 215, in _parse_iso8601_interval
    if "/" not in text:
TypeError: argument of type 'datetime.timedelta' is not iterable
[2024-01-08T04:42:09.850+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:42:09.872+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.528 seconds
[2024-01-08T04:42:40.552+0000] {processor.py:161} INFO - Started process (PID=9337) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:42:40.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:42:40.554+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:42:40.554+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:42:41.079+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:42:41.076+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 90, in <module>
    with DAG(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 525, in __init__
    date = timezone.parse(date)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timezone.py", line 207, in parse
    return pendulum.parse(string, tz=timezone or TIMEZONE, strict=strict)  # type: ignore
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parser.py", line 29, in parse
    return _parse(text, **options)
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parser.py", line 45, in _parse
    parsed = base_parse(text, **options)
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parsing/__init__.py", line 74, in parse
    return _normalize(_parse(text, **_options), **_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parsing/__init__.py", line 115, in _parse
    return _parse_iso8601_interval(text)
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parsing/__init__.py", line 215, in _parse_iso8601_interval
    if "/" not in text:
TypeError: argument of type 'datetime.timedelta' is not iterable
[2024-01-08T04:42:41.079+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:42:41.102+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.554 seconds
[2024-01-08T04:43:11.363+0000] {processor.py:161} INFO - Started process (PID=9401) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:43:11.366+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:43:11.367+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:43:11.366+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:43:11.861+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:43:11.858+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 90, in <module>
    with DAG(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dag.py", line 525, in __init__
    date = timezone.parse(date)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/timezone.py", line 207, in parse
    return pendulum.parse(string, tz=timezone or TIMEZONE, strict=strict)  # type: ignore
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parser.py", line 29, in parse
    return _parse(text, **options)
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parser.py", line 45, in _parse
    parsed = base_parse(text, **options)
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parsing/__init__.py", line 74, in parse
    return _normalize(_parse(text, **_options), **_options)
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parsing/__init__.py", line 115, in _parse
    return _parse_iso8601_interval(text)
  File "/home/airflow/.local/lib/python3.8/site-packages/pendulum/parsing/__init__.py", line 215, in _parse_iso8601_interval
    if "/" not in text:
TypeError: argument of type 'datetime.timedelta' is not iterable
[2024-01-08T04:43:11.861+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:43:11.883+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.525 seconds
[2024-01-08T04:43:30.478+0000] {processor.py:161} INFO - Started process (PID=9426) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:43:30.479+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:43:30.480+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:43:30.480+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:43:31.180+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:43:31.178+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 17, in <module>
    'start_date': fste,
NameError: name 'fste' is not defined
[2024-01-08T04:43:31.181+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:43:31.204+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.732 seconds
[2024-01-08T04:43:34.264+0000] {processor.py:161} INFO - Started process (PID=9439) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:43:34.265+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:43:34.267+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:43:34.266+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:43:34.908+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:43:34.907+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 17, in <module>
    'start_date': datetime(),
TypeError: function missing required argument 'year' (pos 1)
[2024-01-08T04:43:34.909+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:43:34.933+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.676 seconds
[2024-01-08T04:43:37.863+0000] {processor.py:161} INFO - Started process (PID=9457) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:43:37.864+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:43:37.865+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:43:37.865+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:43:38.359+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:43:38.357+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 17, in <module>
    'start_date': datetime(202),
TypeError: function missing required argument 'month' (pos 2)
[2024-01-08T04:43:38.360+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:43:38.380+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.524 seconds
[2024-01-08T04:43:39.665+0000] {processor.py:161} INFO - Started process (PID=9463) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:43:39.666+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:43:39.667+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:43:39.666+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:43:40.161+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:43:40.160+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 17, in <module>
    'start_date': datetime(2024, 1, ),
TypeError: function missing required argument 'day' (pos 3)
[2024-01-08T04:43:40.162+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:43:40.182+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.523 seconds
[2024-01-08T04:43:41.222+0000] {processor.py:161} INFO - Started process (PID=9465) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:43:41.223+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:43:41.224+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:43:41.224+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:43:41.733+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:43:41.855+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:43:41.854+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:43:42.124+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:43:42.124+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:43:42.149+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.933 seconds
[2024-01-08T04:44:12.335+0000] {processor.py:161} INFO - Started process (PID=9530) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:44:12.338+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:44:12.340+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:44:12.339+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:44:12.875+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:44:12.900+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:44:12.899+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:44:12.926+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:44:12.926+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:44:12.950+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.620 seconds
[2024-01-08T04:44:43.925+0000] {processor.py:161} INFO - Started process (PID=9594) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:44:43.927+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:44:43.928+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:44:43.927+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:44:44.461+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:44:44.491+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:44:44.490+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:44:44.524+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:44:44.523+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:44:44.550+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.629 seconds
[2024-01-08T04:45:15.235+0000] {processor.py:161} INFO - Started process (PID=9654) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:45:15.238+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:45:15.239+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:45:15.238+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:45:15.802+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:45:15.828+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:45:15.827+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:45:15.856+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:45:15.856+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:45:15.879+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.650 seconds
[2024-01-08T04:45:46.198+0000] {processor.py:161} INFO - Started process (PID=9716) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:45:46.201+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:45:46.202+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:45:46.201+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:45:46.710+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:45:46.734+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:45:46.733+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:45:46.760+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:45:46.760+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:45:46.784+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.591 seconds
[2024-01-08T04:46:17.113+0000] {processor.py:161} INFO - Started process (PID=9774) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:46:17.116+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:46:17.117+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:46:17.116+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:46:17.623+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:46:17.648+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:46:17.647+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:46:17.675+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:46:17.674+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:46:17.695+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.586 seconds
[2024-01-08T04:46:48.354+0000] {processor.py:161} INFO - Started process (PID=9835) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:46:48.356+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:46:48.357+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:46:48.357+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:46:49.211+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:46:49.252+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:46:49.251+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:46:49.301+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:46:49.301+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:46:49.336+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.988 seconds
[2024-01-08T04:47:19.530+0000] {processor.py:161} INFO - Started process (PID=9894) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:47:19.533+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:47:19.535+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:47:19.534+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:47:20.322+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:47:20.355+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:47:20.354+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:47:20.396+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:47:20.395+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:47:20.426+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.902 seconds
[2024-01-08T04:47:57.026+0000] {processor.py:161} INFO - Started process (PID=31) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:47:57.036+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:47:57.040+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:47:57.039+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:47:58.165+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:47:58.387+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:47:58.386+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:47:58.426+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:47:58.425+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:47:58.456+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.453 seconds
[2024-01-08T04:48:28.846+0000] {processor.py:161} INFO - Started process (PID=91) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:48:28.848+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:48:28.850+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:48:28.850+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:48:29.602+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:48:29.627+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:48:29.626+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:48:29.659+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:48:29.658+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:48:29.684+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.842 seconds
[2024-01-08T04:49:00.002+0000] {processor.py:161} INFO - Started process (PID=151) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:49:00.004+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:49:00.006+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:49:00.005+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:49:00.884+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:49:00.919+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:49:00.916+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:49:00.961+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:49:00.961+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:49:01.000+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.004 seconds
[2024-01-08T04:49:31.146+0000] {processor.py:161} INFO - Started process (PID=212) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:49:31.147+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:49:31.148+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:49:31.148+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:49:31.931+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:49:31.952+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:49:31.951+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:49:31.983+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:49:31.983+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:49:32.004+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.863 seconds
[2024-01-08T04:50:02.323+0000] {processor.py:161} INFO - Started process (PID=275) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:50:02.326+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:50:02.327+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:50:02.327+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:50:03.061+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:50:03.087+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:50:03.086+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:50:03.122+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:50:03.122+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:50:03.149+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.832 seconds
[2024-01-08T04:50:33.791+0000] {processor.py:161} INFO - Started process (PID=335) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:50:33.797+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:50:33.800+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:50:33.799+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:50:35.701+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:50:35.743+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:50:35.742+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:50:35.827+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:50:35.826+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:50:35.857+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 2.081 seconds
[2024-01-08T04:51:06.027+0000] {processor.py:161} INFO - Started process (PID=401) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:51:06.030+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:51:06.032+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:51:06.031+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:51:06.857+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:51:06.883+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:51:06.883+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:51:06.910+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:51:06.909+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:51:06.932+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.910 seconds
[2024-01-08T04:51:37.450+0000] {processor.py:161} INFO - Started process (PID=461) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:51:37.451+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:51:37.452+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:51:37.451+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:51:38.173+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:51:38.199+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:51:38.198+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:51:38.232+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:51:38.231+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:51:38.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.811 seconds
[2024-01-08T04:52:08.846+0000] {processor.py:161} INFO - Started process (PID=521) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:52:08.849+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:52:08.850+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:52:08.849+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:52:09.930+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:52:09.960+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:52:09.959+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:52:09.999+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:52:09.998+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:52:10.029+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.188 seconds
[2024-01-08T04:52:54.694+0000] {processor.py:161} INFO - Started process (PID=31) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:52:54.701+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:52:54.717+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:52:54.716+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:52:56.543+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:52:56.752+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:52:56.751+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:52:56.799+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:52:56.799+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:52:56.847+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 2.166 seconds
[2024-01-08T04:53:27.749+0000] {processor.py:161} INFO - Started process (PID=91) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:53:27.750+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:53:27.753+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:53:27.752+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:53:28.455+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:53:28.480+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:53:28.479+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:53:28.506+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:53:28.506+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:53:28.533+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.789 seconds
[2024-01-08T04:53:58.647+0000] {processor.py:161} INFO - Started process (PID=152) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:53:58.648+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:53:58.651+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:53:58.651+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:53:59.353+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:53:59.375+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:53:59.374+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:53:59.400+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:53:59.400+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:53:59.420+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.778 seconds
[2024-01-08T04:54:29.716+0000] {processor.py:161} INFO - Started process (PID=212) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:54:29.717+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:54:29.720+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:54:29.720+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:54:30.487+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:54:30.516+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:54:30.515+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:54:30.545+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:54:30.545+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:54:30.567+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.856 seconds
[2024-01-08T04:55:00.692+0000] {processor.py:161} INFO - Started process (PID=272) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:55:00.695+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:55:00.698+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:55:00.697+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:55:01.423+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:55:01.450+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:55:01.449+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:55:01.478+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:55:01.478+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:55:01.501+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.814 seconds
[2024-01-08T04:55:31.719+0000] {processor.py:161} INFO - Started process (PID=332) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:55:31.721+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:55:31.725+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:55:31.724+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:55:32.454+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:55:32.476+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:55:32.475+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:55:32.501+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:55:32.501+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:55:32.521+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.807 seconds
[2024-01-08T04:56:02.739+0000] {processor.py:161} INFO - Started process (PID=392) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:56:02.741+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:56:02.744+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:56:02.744+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:56:03.466+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:56:03.487+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:56:03.486+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:56:03.515+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:56:03.514+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:56:03.539+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.806 seconds
[2024-01-08T04:56:33.718+0000] {processor.py:161} INFO - Started process (PID=458) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:56:33.720+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:56:33.724+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:56:33.724+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:56:34.431+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:56:34.451+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:56:34.450+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:56:34.477+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:56:34.477+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:56:34.498+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.787 seconds
[2024-01-08T04:57:04.838+0000] {processor.py:161} INFO - Started process (PID=518) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:57:04.840+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:57:04.843+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:57:04.843+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:57:05.534+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:57:05.557+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:57:05.556+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:57:05.583+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:57:05.582+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:57:05.606+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.774 seconds
[2024-01-08T04:57:35.716+0000] {processor.py:161} INFO - Started process (PID=578) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:57:35.718+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:57:35.722+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:57:35.721+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:57:36.464+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:57:36.491+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:57:36.490+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:57:36.523+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:57:36.523+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:57:36.548+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.838 seconds
[2024-01-08T04:58:06.886+0000] {processor.py:161} INFO - Started process (PID=638) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:58:06.887+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:58:06.890+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:58:06.889+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:58:07.583+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:58:07.605+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:58:07.604+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:58:07.628+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:58:07.628+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:58:07.648+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.768 seconds
[2024-01-08T04:58:37.831+0000] {processor.py:161} INFO - Started process (PID=698) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:58:37.833+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:58:37.836+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:58:37.835+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:58:38.543+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:58:38.573+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:58:38.572+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:58:38.600+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:58:38.600+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:58:38.624+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.798 seconds
[2024-01-08T04:59:09.008+0000] {processor.py:161} INFO - Started process (PID=758) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:59:09.010+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:59:09.015+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:59:09.014+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:59:10.038+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:59:10.070+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:59:10.069+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:59:10.109+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:59:10.109+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:59:10.157+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.156 seconds
[2024-01-08T04:59:40.630+0000] {processor.py:161} INFO - Started process (PID=819) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:59:40.632+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T04:59:40.637+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:59:40.636+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:59:41.655+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T04:59:41.686+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:59:41.685+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T04:59:41.725+0000] {logging_mixin.py:188} INFO - [2024-01-08T04:59:41.725+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T04:59:41.754+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.131 seconds
[2024-01-08T05:00:12.027+0000] {processor.py:161} INFO - Started process (PID=883) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:00:12.028+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:00:12.031+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:00:12.031+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:00:12.893+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:00:12.922+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:00:12.921+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:00:12.958+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:00:12.958+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T05:00:12.989+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.967 seconds
[2024-01-08T05:00:43.132+0000] {processor.py:161} INFO - Started process (PID=942) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:00:43.135+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:00:43.138+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:00:43.138+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:00:43.825+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:00:43.845+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:00:43.844+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:00:43.869+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:00:43.869+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T05:00:43.888+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.761 seconds
[2024-01-08T05:01:14.724+0000] {processor.py:161} INFO - Started process (PID=1002) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:01:14.727+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:01:14.730+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:01:14.729+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:01:15.492+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:01:15.518+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:01:15.517+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:01:15.547+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:01:15.547+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T05:01:15.567+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.848 seconds
[2024-01-08T05:01:46.344+0000] {processor.py:161} INFO - Started process (PID=1062) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:01:46.345+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:01:46.348+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:01:46.348+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:01:47.120+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:01:47.255+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:01:47.254+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:01:47.279+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:01:47.279+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T05:01:47.301+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.963 seconds
[2024-01-08T05:02:17.673+0000] {processor.py:161} INFO - Started process (PID=1122) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:02:17.675+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:02:17.679+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:02:17.678+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:02:18.377+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:02:18.508+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:02:18.507+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:02:18.533+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:02:18.533+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T05:02:18.560+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.892 seconds
[2024-01-08T05:02:49.119+0000] {processor.py:161} INFO - Started process (PID=1182) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:02:49.120+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:02:49.123+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:02:49.123+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:02:49.893+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:02:49.914+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:02:49.913+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:02:49.941+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:02:49.941+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-07T00:00:00+00:00, run_after=2024-01-08T00:00:00+00:00
[2024-01-08T05:02:49.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.848 seconds
[2024-01-08T05:03:20.481+0000] {processor.py:161} INFO - Started process (PID=1247) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:03:20.484+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:03:20.488+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:03:20.487+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:03:21.310+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:03:21.338+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:03:21.338+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:03:21.375+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:03:21.374+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:03:21.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.924 seconds
[2024-01-08T05:03:51.836+0000] {processor.py:161} INFO - Started process (PID=1307) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:03:51.837+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:03:51.840+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:03:51.840+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:03:52.526+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:03:52.546+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:03:52.545+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:03:52.573+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:03:52.573+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:03:52.593+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.762 seconds
[2024-01-08T05:04:23.413+0000] {processor.py:161} INFO - Started process (PID=1367) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:04:23.416+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:04:23.419+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:04:23.419+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:04:24.122+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:04:24.149+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:04:24.148+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:04:24.183+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:04:24.183+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:04:24.209+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.803 seconds
[2024-01-08T05:04:54.941+0000] {processor.py:161} INFO - Started process (PID=1427) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:04:54.943+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:04:54.947+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:04:54.947+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:04:55.687+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:04:55.709+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:04:55.709+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:04:55.741+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:04:55.741+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:04:55.764+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.830 seconds
[2024-01-08T05:05:26.206+0000] {processor.py:161} INFO - Started process (PID=1487) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:05:26.208+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:05:26.210+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:05:26.210+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:05:26.924+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:05:26.948+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:05:26.947+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:05:26.976+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:05:26.975+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:05:26.996+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.794 seconds
[2024-01-08T05:05:54.520+0000] {processor.py:161} INFO - Started process (PID=1550) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:05:54.523+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:05:54.526+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:05:54.525+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:05:55.210+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:05:55.231+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:05:55.230+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:05:55.257+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:05:55.257+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:05:55.281+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.765 seconds
[2024-01-08T05:06:26.124+0000] {processor.py:161} INFO - Started process (PID=1614) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:06:26.126+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:06:26.130+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:06:26.129+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:06:26.891+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:06:26.912+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:06:26.911+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:06:26.939+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:06:26.939+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:06:26.958+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.841 seconds
[2024-01-08T05:06:57.672+0000] {processor.py:161} INFO - Started process (PID=1674) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:06:57.675+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:06:57.678+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:06:57.678+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:06:58.462+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:06:58.483+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:06:58.483+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:06:58.511+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:06:58.511+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:06:58.533+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.866 seconds
[2024-01-08T05:07:29.156+0000] {processor.py:161} INFO - Started process (PID=1734) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:07:29.157+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:07:29.160+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:07:29.159+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:07:29.860+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:07:29.859+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 99, in <module>
    datalake_files = os.listdir(config_dir_path)
FileNotFoundError: [Errno 2] No such file or directory: '/opt/airflow/data/daily_datalake'
[2024-01-08T05:07:29.861+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:07:29.881+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.730 seconds
[2024-01-08T05:08:00.020+0000] {processor.py:161} INFO - Started process (PID=1799) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:08:00.022+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:08:00.026+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:08:00.025+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:08:00.946+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:08:00.980+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:08:00.979+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:08:01.017+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:08:01.017+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:08:01.047+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.033 seconds
[2024-01-08T05:08:31.610+0000] {processor.py:161} INFO - Started process (PID=1865) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:08:31.613+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:08:31.616+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:08:31.616+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:08:32.434+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:08:32.464+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:08:32.463+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:08:32.502+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:08:32.501+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:08:32.525+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.919 seconds
[2024-01-08T05:09:03.295+0000] {processor.py:161} INFO - Started process (PID=1929) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:09:03.296+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:09:03.300+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:09:03.300+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:09:04.039+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:09:04.060+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:09:04.059+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:09:04.084+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:09:04.084+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:09:04.108+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.818 seconds
[2024-01-08T05:12:56.396+0000] {processor.py:161} INFO - Started process (PID=2378) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:12:56.417+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:12:56.419+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:12:56.419+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:12:56.956+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:12:57.081+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:12:57.080+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:12:57.107+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:12:57.107+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:12:57.134+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.746 seconds
[2024-01-08T05:13:27.717+0000] {processor.py:161} INFO - Started process (PID=2438) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:13:27.719+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:13:27.721+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:13:27.720+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:13:28.296+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:13:28.324+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:13:28.323+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:13:28.355+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:13:28.355+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:13:28.379+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.670 seconds
[2024-01-08T05:13:58.961+0000] {processor.py:161} INFO - Started process (PID=2498) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:13:58.964+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:13:58.965+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:13:58.964+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:13:59.476+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:13:59.500+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:13:59.499+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:13:59.528+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:13:59.528+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:13:59.551+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.596 seconds
[2024-01-08T05:14:29.621+0000] {processor.py:161} INFO - Started process (PID=2558) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:14:29.623+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:14:29.625+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:14:29.625+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:14:30.139+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:14:30.163+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:14:30.163+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:14:30.190+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:14:30.190+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:14:30.212+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.599 seconds
[2024-01-08T05:15:00.811+0000] {processor.py:161} INFO - Started process (PID=2619) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:15:00.814+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:15:00.815+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:15:00.815+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:15:01.322+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:15:01.346+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:15:01.345+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:15:01.375+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:15:01.375+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:15:01.399+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.593 seconds
[2024-01-08T05:15:31.553+0000] {processor.py:161} INFO - Started process (PID=2679) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:15:31.556+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:15:31.557+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:15:31.557+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:15:32.061+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:15:32.086+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:15:32.085+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:15:32.116+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:15:32.116+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:15:32.140+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.592 seconds
[2024-01-08T05:16:03.036+0000] {processor.py:161} INFO - Started process (PID=2739) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:16:03.038+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:16:03.039+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:16:03.039+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:16:03.527+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:16:03.551+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:16:03.551+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:16:03.583+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:16:03.582+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:16:03.610+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.581 seconds
[2024-01-08T05:16:34.608+0000] {processor.py:161} INFO - Started process (PID=2799) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:16:34.609+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:16:34.611+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:16:34.610+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:16:35.131+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:16:35.155+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:16:35.154+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:16:35.189+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:16:35.189+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:16:35.213+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.611 seconds
[2024-01-08T05:17:05.891+0000] {processor.py:161} INFO - Started process (PID=2859) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:17:05.894+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:17:05.896+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:17:05.895+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:17:06.474+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:17:06.497+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:17:06.496+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:17:06.527+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:17:06.526+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:17:06.550+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.665 seconds
[2024-01-08T05:17:37.181+0000] {processor.py:161} INFO - Started process (PID=2926) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:17:37.183+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:17:37.184+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:17:37.183+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:17:37.696+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:17:37.721+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:17:37.720+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:17:37.749+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:17:37.748+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:17:37.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.596 seconds
[2024-01-08T05:18:08.218+0000] {processor.py:161} INFO - Started process (PID=2986) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:18:08.221+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:18:08.222+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:18:08.221+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:18:08.707+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:18:08.730+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:18:08.730+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:18:08.757+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:18:08.757+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:18:08.780+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.567 seconds
[2024-01-08T05:18:38.926+0000] {processor.py:161} INFO - Started process (PID=3045) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:18:38.930+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:18:38.931+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:18:38.931+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:18:39.651+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:18:39.674+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:18:39.674+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:18:39.710+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:18:39.710+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:18:39.732+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.813 seconds
[2024-01-08T05:19:09.827+0000] {processor.py:161} INFO - Started process (PID=3105) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:19:09.828+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:19:09.829+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:19:09.829+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:19:10.318+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:19:10.345+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:19:10.344+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:19:10.375+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:19:10.374+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:19:10.397+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.575 seconds
[2024-01-08T05:19:41.054+0000] {processor.py:161} INFO - Started process (PID=3165) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:19:41.057+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:19:41.058+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:19:41.058+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:19:41.548+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:19:41.573+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:19:41.573+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:19:41.602+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:19:41.602+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:19:41.629+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.580 seconds
[2024-01-08T05:20:11.859+0000] {processor.py:161} INFO - Started process (PID=3225) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:20:11.861+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:20:11.863+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:20:11.862+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:20:12.439+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:20:12.473+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:20:12.471+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:20:12.509+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:20:12.508+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:20:12.536+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.683 seconds
[2024-01-08T05:20:42.751+0000] {processor.py:161} INFO - Started process (PID=3285) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:20:42.754+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:20:42.755+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:20:42.755+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:20:43.323+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:20:43.355+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:20:43.354+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:20:43.392+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:20:43.391+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:20:43.418+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.673 seconds
[2024-01-08T05:21:13.801+0000] {processor.py:161} INFO - Started process (PID=3345) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:21:13.802+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:21:13.804+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:21:13.803+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:21:14.454+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:21:14.477+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:21:14.476+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:21:14.505+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:21:14.505+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:21:14.526+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.732 seconds
[2024-01-08T05:21:44.745+0000] {processor.py:161} INFO - Started process (PID=3405) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:21:44.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:21:44.750+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:21:44.750+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:21:45.384+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:21:45.409+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:21:45.409+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:21:45.443+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:21:45.443+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:21:45.474+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.737 seconds
[2024-01-08T05:22:15.551+0000] {processor.py:161} INFO - Started process (PID=3464) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:22:15.552+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:22:15.553+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:22:15.552+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:22:16.270+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:22:16.291+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:22:16.291+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:22:16.318+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:22:16.318+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:22:16.340+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.794 seconds
[2024-01-08T05:22:46.459+0000] {processor.py:161} INFO - Started process (PID=3524) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:22:46.461+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:22:46.462+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:22:46.462+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:22:47.152+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:22:47.172+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:22:47.172+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:22:47.200+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:22:47.199+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:22:47.220+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.767 seconds
[2024-01-08T05:23:17.290+0000] {processor.py:161} INFO - Started process (PID=3584) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:23:17.292+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:23:17.293+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:23:17.293+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:23:17.965+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:23:17.986+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:23:17.985+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:23:18.011+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:23:18.011+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:23:18.036+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.752 seconds
[2024-01-08T05:23:48.226+0000] {processor.py:161} INFO - Started process (PID=3644) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:23:48.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:23:48.230+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:23:48.229+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:23:48.925+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:23:48.945+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:23:48.944+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:23:48.969+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:23:48.969+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:23:48.991+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.769 seconds
[2024-01-08T05:24:19.883+0000] {processor.py:161} INFO - Started process (PID=3706) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:24:19.884+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:24:19.885+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:24:19.885+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:24:20.586+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:24:20.608+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:24:20.607+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:24:20.639+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:24:20.639+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:24:20.662+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.784 seconds
[2024-01-08T05:24:51.244+0000] {processor.py:161} INFO - Started process (PID=3766) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:24:51.247+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:24:51.249+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:24:51.248+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:24:51.967+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:24:51.987+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:24:51.986+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:24:52.013+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:24:52.013+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:24:52.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.798 seconds
[2024-01-08T05:25:22.806+0000] {processor.py:161} INFO - Started process (PID=3826) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:25:22.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:25:22.810+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:25:22.810+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:25:23.579+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:25:23.599+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:25:23.598+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:25:23.637+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:25:23.637+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:25:23.660+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.860 seconds
[2024-01-08T05:25:54.359+0000] {processor.py:161} INFO - Started process (PID=3887) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:25:54.360+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:25:54.361+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:25:54.361+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:25:55.083+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:25:55.104+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:25:55.104+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:25:55.130+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:25:55.130+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:25:55.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.799 seconds
[2024-01-08T05:26:25.994+0000] {processor.py:161} INFO - Started process (PID=3947) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:26:25.997+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:26:25.999+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:26:25.998+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:26:26.823+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:26:26.843+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:26:26.842+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:26:26.876+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:26:26.876+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:26:26.900+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.912 seconds
[2024-01-08T05:26:57.428+0000] {processor.py:161} INFO - Started process (PID=4007) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:26:57.431+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:26:57.433+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:26:57.432+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:26:58.477+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:26:58.504+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:26:58.503+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:26:58.536+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:26:58.536+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:26:58.559+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.139 seconds
[2024-01-08T05:27:28.663+0000] {processor.py:161} INFO - Started process (PID=4067) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:27:28.665+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:27:28.667+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:27:28.666+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:27:29.343+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:27:29.363+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:27:29.362+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:27:29.392+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:27:29.392+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:27:29.415+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.757 seconds
[2024-01-08T05:27:59.871+0000] {processor.py:161} INFO - Started process (PID=4127) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:27:59.873+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:27:59.874+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:27:59.874+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:28:00.568+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:28:00.588+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:28:00.587+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:28:00.620+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:28:00.619+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:28:00.642+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.777 seconds
[2024-01-08T05:28:31.420+0000] {processor.py:161} INFO - Started process (PID=4187) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:28:31.421+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:28:31.422+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:28:31.422+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:28:32.144+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:28:32.164+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:28:32.163+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:28:32.189+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:28:32.189+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:28:32.216+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.801 seconds
[2024-01-08T05:29:02.909+0000] {processor.py:161} INFO - Started process (PID=4247) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:29:02.918+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:29:02.921+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:29:02.920+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:29:04.323+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:29:04.366+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:29:04.364+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:29:04.402+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:29:04.401+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:29:04.433+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.538 seconds
[2024-01-08T05:29:35.041+0000] {processor.py:161} INFO - Started process (PID=4307) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:29:35.043+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:29:35.045+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:29:35.044+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:29:35.757+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:29:35.777+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:29:35.777+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:29:35.809+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:29:35.809+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:29:35.835+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.799 seconds
[2024-01-08T05:30:06.343+0000] {processor.py:161} INFO - Started process (PID=4367) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:30:06.345+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:30:06.346+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:30:06.345+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:30:07.142+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:30:07.162+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:30:07.162+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:30:07.188+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:30:07.188+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:30:07.214+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.876 seconds
[2024-01-08T05:30:37.282+0000] {processor.py:161} INFO - Started process (PID=4432) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:30:37.284+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:30:37.286+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:30:37.285+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:30:38.043+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:30:38.066+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:30:38.065+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:30:38.095+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:30:38.094+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:30:38.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.840 seconds
[2024-01-08T05:31:08.185+0000] {processor.py:161} INFO - Started process (PID=4501) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:31:08.187+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:31:08.188+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:31:08.188+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:31:08.941+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:31:08.966+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:31:08.965+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:31:08.994+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:31:08.994+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:31:09.024+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.845 seconds
[2024-01-08T05:31:39.591+0000] {processor.py:161} INFO - Started process (PID=4572) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:31:39.594+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T05:31:39.595+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:31:39.595+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:31:40.543+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T05:31:40.565+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:31:40.564+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T05:31:40.598+0000] {logging_mixin.py:188} INFO - [2024-01-08T05:31:40.598+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T05:31:40.628+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.043 seconds
[2024-01-08T06:34:03.360+0000] {processor.py:161} INFO - Started process (PID=31) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:34:03.371+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:34:03.378+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:34:03.377+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:34:04.668+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:34:04.902+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:34:04.901+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:34:04.942+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:34:04.941+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:34:04.983+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.633 seconds
[2024-01-08T06:34:35.482+0000] {processor.py:161} INFO - Started process (PID=95) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:34:35.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:34:35.502+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:34:35.501+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:34:36.543+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:34:36.568+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:34:36.567+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:34:36.598+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:34:36.597+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:34:36.661+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.185 seconds
[2024-01-08T06:35:06.931+0000] {processor.py:161} INFO - Started process (PID=156) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:35:06.933+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:35:06.936+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:35:06.936+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:35:07.659+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:35:07.678+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:35:07.678+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:35:07.707+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:35:07.707+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:35:07.729+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.806 seconds
[2024-01-08T06:35:38.072+0000] {processor.py:161} INFO - Started process (PID=219) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:35:38.079+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:35:38.084+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:35:38.084+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:35:38.921+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:35:38.947+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:35:38.946+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:35:38.975+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:35:38.975+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:35:38.996+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.932 seconds
[2024-01-08T06:36:09.372+0000] {processor.py:161} INFO - Started process (PID=283) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:36:09.373+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:36:09.377+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:36:09.376+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:36:10.097+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:36:10.120+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:36:10.117+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:36:10.145+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:36:10.145+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:36:10.165+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.799 seconds
[2024-01-08T06:36:40.678+0000] {processor.py:161} INFO - Started process (PID=343) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:36:40.687+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:36:40.691+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:36:40.690+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:36:41.391+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:36:41.414+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:36:41.413+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:36:41.442+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:36:41.442+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:36:41.466+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.793 seconds
[2024-01-08T06:37:11.916+0000] {processor.py:161} INFO - Started process (PID=403) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:37:11.917+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:37:11.920+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:37:11.920+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:37:12.606+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:37:12.635+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:37:12.634+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:37:12.664+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:37:12.663+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:37:12.689+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.779 seconds
[2024-01-08T06:37:43.072+0000] {processor.py:161} INFO - Started process (PID=467) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:37:43.081+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:37:43.084+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:37:43.084+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:37:43.787+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:37:43.813+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:37:43.812+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:37:43.844+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:37:43.844+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:37:43.869+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.802 seconds
[2024-01-08T06:38:14.307+0000] {processor.py:161} INFO - Started process (PID=527) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:38:14.308+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:38:14.311+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:38:14.311+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:38:15.019+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:38:15.039+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:38:15.038+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:38:15.068+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:38:15.068+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:38:15.092+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.790 seconds
[2024-01-08T06:38:45.488+0000] {processor.py:161} INFO - Started process (PID=588) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:38:45.515+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:38:45.520+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:38:45.520+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:38:46.355+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:38:46.379+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:38:46.378+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:38:46.418+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:38:46.418+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:38:46.444+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.961 seconds
[2024-01-08T06:39:16.893+0000] {processor.py:161} INFO - Started process (PID=659) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:39:16.895+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:39:16.899+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:39:16.898+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:39:17.809+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:39:17.834+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:39:17.833+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:39:17.872+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:39:17.872+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:39:17.901+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.014 seconds
[2024-01-08T06:39:48.025+0000] {processor.py:161} INFO - Started process (PID=725) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:39:48.026+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:39:48.031+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:39:48.030+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:39:48.824+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:39:48.845+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:39:48.844+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:39:48.878+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:39:48.878+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:39:48.903+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.884 seconds
[2024-01-08T06:40:19.127+0000] {processor.py:161} INFO - Started process (PID=789) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:40:19.143+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:40:19.147+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:40:19.146+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:40:20.021+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:40:20.048+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:40:20.047+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:40:20.089+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:40:20.088+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:40:20.112+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.993 seconds
[2024-01-08T06:40:50.831+0000] {processor.py:161} INFO - Started process (PID=861) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:40:50.832+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:40:50.835+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:40:50.835+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:40:51.565+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:40:51.593+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:40:51.592+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:40:51.636+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:40:51.635+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:40:51.668+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.842 seconds
[2024-01-08T06:41:22.542+0000] {processor.py:161} INFO - Started process (PID=930) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:41:22.555+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:41:22.559+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:41:22.558+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:41:23.283+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:41:23.304+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:41:23.303+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:41:23.332+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:41:23.332+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:41:23.353+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.815 seconds
[2024-01-08T06:41:53.419+0000] {processor.py:161} INFO - Started process (PID=994) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:41:53.421+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:41:53.424+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:41:53.423+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:41:54.118+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:41:54.142+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:41:54.141+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:41:54.174+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:41:54.174+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:41:54.202+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.787 seconds
[2024-01-08T06:42:25.131+0000] {processor.py:161} INFO - Started process (PID=1059) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:42:25.153+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:42:25.159+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:42:25.159+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:42:25.989+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:42:26.012+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:42:26.011+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:42:26.037+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:42:26.037+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:42:26.060+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.939 seconds
[2024-01-08T06:42:56.666+0000] {processor.py:161} INFO - Started process (PID=1122) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:42:56.668+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:42:56.671+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:42:56.671+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:42:57.370+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:42:57.395+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:42:57.394+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:42:57.430+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:42:57.430+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:42:57.453+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.793 seconds
[2024-01-08T06:43:27.510+0000] {processor.py:161} INFO - Started process (PID=1184) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:43:27.511+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:43:27.514+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:43:27.513+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:43:28.205+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:43:28.232+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:43:28.231+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:43:28.257+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:43:28.257+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:43:28.277+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.772 seconds
[2024-01-08T06:43:58.664+0000] {processor.py:161} INFO - Started process (PID=1247) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:43:58.667+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:43:58.672+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:43:58.671+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:43:59.491+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:43:59.517+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:43:59.516+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:43:59.546+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:43:59.546+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:43:59.571+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.914 seconds
[2024-01-08T06:44:29.847+0000] {processor.py:161} INFO - Started process (PID=1307) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:44:29.849+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:44:29.852+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:44:29.852+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:44:30.630+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:44:30.653+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:44:30.652+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:44:30.689+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:44:30.688+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:44:30.716+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.875 seconds
[2024-01-08T06:45:01.217+0000] {processor.py:161} INFO - Started process (PID=1367) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:45:01.222+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:45:01.226+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:45:01.226+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:45:02.000+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:45:02.021+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:45:02.020+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:45:02.051+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:45:02.051+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:45:02.084+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.871 seconds
[2024-01-08T06:45:32.581+0000] {processor.py:161} INFO - Started process (PID=1431) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:45:32.582+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:45:32.585+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:45:32.585+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:45:33.291+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:45:33.313+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:45:33.313+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:45:33.342+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:45:33.342+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:45:33.363+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.788 seconds
[2024-01-08T06:45:55.885+0000] {processor.py:161} INFO - Started process (PID=1469) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:45:55.887+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:45:55.890+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:45:55.890+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:45:56.636+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:45:56.747+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:45:56.746+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:45:56.772+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:45:56.771+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:45:56.796+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.916 seconds
[2024-01-08T06:46:27.432+0000] {processor.py:161} INFO - Started process (PID=1534) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:46:27.434+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:46:27.437+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:46:27.436+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:46:28.098+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:46:28.118+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:46:28.117+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:46:28.142+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:46:28.142+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:46:28.162+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.734 seconds
[2024-01-08T06:46:59.079+0000] {processor.py:161} INFO - Started process (PID=1595) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:46:59.081+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:46:59.084+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:46:59.084+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:46:59.812+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:46:59.832+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:46:59.832+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:46:59.858+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:46:59.858+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:46:59.881+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.807 seconds
[2024-01-08T06:47:29.997+0000] {processor.py:161} INFO - Started process (PID=1660) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:47:29.999+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:47:30.003+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:47:30.002+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:47:30.882+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:47:30.908+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:47:30.907+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:47:30.947+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:47:30.946+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:47:30.974+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.983 seconds
[2024-01-08T06:48:01.189+0000] {processor.py:161} INFO - Started process (PID=1721) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:48:01.192+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:48:01.195+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:48:01.195+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:48:02.016+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:48:02.044+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:48:02.043+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:48:02.084+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:48:02.084+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:48:02.112+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.927 seconds
[2024-01-08T06:48:32.286+0000] {processor.py:161} INFO - Started process (PID=1787) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:48:32.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:48:32.291+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:48:32.291+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:48:32.947+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:48:32.967+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:48:32.966+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:48:32.993+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:48:32.993+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:48:33.013+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.734 seconds
[2024-01-08T06:49:03.169+0000] {processor.py:161} INFO - Started process (PID=1848) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:49:03.170+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T06:49:03.173+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:49:03.173+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:49:03.846+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T06:49:03.868+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:49:03.868+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T06:49:03.893+0000] {logging_mixin.py:188} INFO - [2024-01-08T06:49:03.893+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T06:49:03.916+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.752 seconds
[2024-01-08T07:16:11.874+0000] {processor.py:161} INFO - Started process (PID=30) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:16:11.895+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:16:11.901+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:16:11.900+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:16:13.395+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:16:13.657+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:16:13.647+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:16:13.702+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:16:13.702+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:16:13.740+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.890 seconds
[2024-01-08T07:16:44.255+0000] {processor.py:161} INFO - Started process (PID=92) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:16:44.258+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:16:44.262+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:16:44.261+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:16:45.044+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:16:45.067+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:16:45.066+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:16:45.097+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:16:45.096+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:16:45.121+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.872 seconds
[2024-01-08T07:17:15.957+0000] {processor.py:161} INFO - Started process (PID=155) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:17:15.960+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:17:15.965+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:17:15.965+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:17:16.781+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:17:16.803+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:17:16.802+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:17:16.836+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:17:16.835+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:17:16.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.916 seconds
[2024-01-08T07:17:47.536+0000] {processor.py:161} INFO - Started process (PID=219) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:17:47.537+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:17:47.541+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:17:47.541+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:17:48.419+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:17:48.442+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:17:48.441+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:17:48.475+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:17:48.475+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:17:48.501+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.971 seconds
[2024-01-08T07:18:18.653+0000] {processor.py:161} INFO - Started process (PID=285) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:18:18.655+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:18:18.659+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:18:18.658+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:18:19.461+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:18:19.482+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:18:19.482+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:18:19.512+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:18:19.511+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:18:19.536+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.888 seconds
[2024-01-08T07:18:49.691+0000] {processor.py:161} INFO - Started process (PID=345) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:18:49.693+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:18:49.696+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:18:49.696+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:18:50.438+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:18:50.569+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:18:50.568+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:18:50.584+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:18:50.583+0000] {dag.py:3055} INFO - Creating ORM DAG for etl_to_datalake
[2024-01-08T07:18:50.597+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:18:50.597+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T07:18:50.622+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.936 seconds
[2024-01-08T07:19:21.369+0000] {processor.py:161} INFO - Started process (PID=407) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:19:21.387+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:19:21.391+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:19:21.390+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:19:22.226+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:19:22.358+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:19:22.357+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:19:22.386+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:19:22.386+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T07:19:22.418+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.055 seconds
[2024-01-08T07:19:53.385+0000] {processor.py:161} INFO - Started process (PID=480) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:19:53.387+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:19:53.390+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:19:53.390+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:19:54.203+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:19:54.226+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:19:54.226+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:19:54.256+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:19:54.256+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T07:19:54.283+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.904 seconds
[2024-01-08T07:20:24.539+0000] {processor.py:161} INFO - Started process (PID=541) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:20:24.540+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:20:24.544+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:20:24.543+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:20:25.369+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:20:25.392+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:20:25.391+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:20:25.428+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:20:25.428+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T07:20:25.456+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.923 seconds
[2024-01-08T07:20:55.648+0000] {processor.py:161} INFO - Started process (PID=608) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:20:55.651+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:20:55.655+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:20:55.654+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:20:56.476+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:20:56.506+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:20:56.505+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:20:56.537+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:20:56.537+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T07:20:56.564+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.923 seconds
[2024-01-08T07:21:27.064+0000] {processor.py:161} INFO - Started process (PID=686) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:21:27.066+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:21:27.071+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:21:27.070+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:21:28.002+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:21:28.033+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:21:28.032+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:21:28.076+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:21:28.075+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:21:28.106+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.049 seconds
[2024-01-08T07:21:58.400+0000] {processor.py:161} INFO - Started process (PID=747) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:21:58.404+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:21:58.408+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:21:58.408+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:21:59.477+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:21:59.503+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:21:59.502+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:21:59.553+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:21:59.552+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:21:59.586+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.192 seconds
[2024-01-08T07:22:29.651+0000] {processor.py:161} INFO - Started process (PID=811) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:22:29.653+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:22:29.656+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:22:29.656+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:22:30.472+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:22:30.495+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:22:30.495+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:22:30.525+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:22:30.524+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:22:30.551+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.905 seconds
[2024-01-08T07:23:00.800+0000] {processor.py:161} INFO - Started process (PID=875) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:23:00.803+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:23:00.806+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:23:00.805+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:23:01.516+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:23:01.537+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:23:01.536+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:23:01.565+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:23:01.564+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:23:01.589+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.794 seconds
[2024-01-08T07:23:31.645+0000] {processor.py:161} INFO - Started process (PID=935) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:23:31.648+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:23:31.651+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:23:31.651+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:23:32.364+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:23:32.386+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:23:32.386+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:23:32.416+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:23:32.416+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:23:32.444+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.803 seconds
[2024-01-08T07:24:03.143+0000] {processor.py:161} INFO - Started process (PID=995) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:24:03.146+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:24:03.150+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:24:03.150+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:24:04.046+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:24:04.075+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:24:04.075+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:24:04.110+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:24:04.110+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:24:04.138+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.000 seconds
[2024-01-08T07:24:34.400+0000] {processor.py:161} INFO - Started process (PID=1061) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:24:34.403+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:24:34.407+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:24:34.407+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:24:35.203+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:24:35.226+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:24:35.225+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:24:35.255+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:24:35.255+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:24:35.284+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.892 seconds
[2024-01-08T07:25:06.274+0000] {processor.py:161} INFO - Started process (PID=1127) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:25:06.285+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:25:06.288+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:25:06.288+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:25:07.049+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:25:07.072+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:25:07.071+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:25:07.104+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:25:07.104+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:25:07.129+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.861 seconds
[2024-01-08T07:25:37.470+0000] {processor.py:161} INFO - Started process (PID=1187) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:25:37.471+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:25:37.476+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:25:37.475+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:25:38.218+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:25:38.355+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:25:38.354+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:25:38.377+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:25:38.375+0000] {dag.py:3055} INFO - Creating ORM DAG for etl_to_datalake
[2024-01-08T07:25:38.393+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:25:38.392+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T07:25:38.418+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.954 seconds
[2024-01-08T07:26:08.888+0000] {processor.py:161} INFO - Started process (PID=1247) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:26:08.891+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:26:08.894+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:26:08.894+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:26:09.787+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:26:09.815+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:26:09.814+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:26:09.849+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:26:09.849+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T07:26:09.877+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.994 seconds
[2024-01-08T07:26:39.914+0000] {processor.py:161} INFO - Started process (PID=1307) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:26:39.916+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:26:39.919+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:26:39.918+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:26:40.625+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:26:40.649+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:26:40.649+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:26:40.676+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:26:40.676+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T07:26:40.703+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.794 seconds
[2024-01-08T07:27:11.366+0000] {processor.py:161} INFO - Started process (PID=1367) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:27:11.369+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:27:11.372+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:27:11.372+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:27:12.098+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:27:12.122+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:27:12.122+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:27:12.149+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:27:12.149+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T07:27:12.177+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.816 seconds
[2024-01-08T07:27:42.250+0000] {processor.py:161} INFO - Started process (PID=1427) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:27:42.251+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:27:42.254+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:27:42.254+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:27:42.962+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:27:42.986+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:27:42.985+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:27:43.012+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:27:43.012+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T07:27:43.034+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.789 seconds
[2024-01-08T07:28:13.783+0000] {processor.py:161} INFO - Started process (PID=1487) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:28:13.786+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:28:13.790+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:28:13.789+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:28:14.552+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:28:14.575+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:28:14.574+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:28:14.600+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:28:14.600+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T07:28:14.624+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.846 seconds
[2024-01-08T07:28:44.679+0000] {processor.py:161} INFO - Started process (PID=1547) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:28:44.682+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:28:44.687+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:28:44.686+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:28:45.418+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:28:45.446+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:28:45.446+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:28:45.473+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:28:45.473+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T07:28:45.501+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.826 seconds
[2024-01-08T07:29:15.576+0000] {processor.py:161} INFO - Started process (PID=1607) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:29:15.577+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:29:15.581+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:29:15.580+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:29:16.430+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:29:16.456+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:29:16.455+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:29:16.488+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:29:16.487+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T07:29:16.513+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.944 seconds
[2024-01-08T07:29:46.955+0000] {processor.py:161} INFO - Started process (PID=1675) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:29:46.962+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:29:46.969+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:29:46.969+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:29:48.323+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:29:48.372+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:29:48.370+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:29:48.424+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:29:48.424+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:29:48.465+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.522 seconds
[2024-01-08T07:30:18.557+0000] {processor.py:161} INFO - Started process (PID=1735) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:30:18.558+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:30:18.562+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:30:18.562+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:30:19.327+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:30:19.362+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:30:19.361+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:30:19.404+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:30:19.404+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:30:19.438+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.887 seconds
[2024-01-08T07:30:49.669+0000] {processor.py:161} INFO - Started process (PID=1803) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:30:49.672+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:30:49.676+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:30:49.676+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:30:50.525+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:30:50.551+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:30:50.550+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:30:50.579+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:30:50.579+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:30:50.605+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.942 seconds
[2024-01-08T07:31:20.737+0000] {processor.py:161} INFO - Started process (PID=1863) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:31:20.738+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:31:20.742+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:31:20.741+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:31:21.552+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:31:21.575+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:31:21.574+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:31:21.603+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:31:21.603+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:31:21.629+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.899 seconds
[2024-01-08T07:42:42.023+0000] {processor.py:161} INFO - Started process (PID=31) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:42:42.061+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:42:42.067+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:42:42.066+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:42:43.812+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:42:44.019+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:42:44.018+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:42:44.065+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:42:44.064+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:42:44.102+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 2.097 seconds
[2024-01-08T07:43:08.514+0000] {processor.py:161} INFO - Started process (PID=31) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:43:08.517+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:43:08.520+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:43:08.520+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:43:09.280+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:43:09.310+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:43:09.310+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:43:09.340+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:43:09.340+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:43:09.366+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.857 seconds
[2024-01-08T07:43:39.556+0000] {processor.py:161} INFO - Started process (PID=91) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:43:39.558+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:43:39.562+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:43:39.561+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:43:40.287+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:43:40.311+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:43:40.310+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:43:40.341+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:43:40.341+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:43:40.367+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.817 seconds
[2024-01-08T07:44:10.794+0000] {processor.py:161} INFO - Started process (PID=152) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:44:10.797+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:44:10.799+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:44:10.798+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:44:11.561+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:44:11.590+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:44:11.589+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:44:11.620+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:44:11.620+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:44:11.651+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.863 seconds
[2024-01-08T07:44:41.710+0000] {processor.py:161} INFO - Started process (PID=217) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:44:41.713+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:44:41.715+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:44:41.714+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:44:42.485+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:44:42.507+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:44:42.506+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:44:42.544+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:44:42.543+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:44:42.572+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.869 seconds
[2024-01-08T07:45:12.692+0000] {processor.py:161} INFO - Started process (PID=282) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:45:12.695+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:45:12.696+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:45:12.696+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:45:13.463+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:45:13.487+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:45:13.484+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:45:13.515+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:45:13.515+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:45:13.541+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.856 seconds
[2024-01-08T07:45:44.456+0000] {processor.py:161} INFO - Started process (PID=348) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:45:44.458+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:45:44.459+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:45:44.459+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:45:45.354+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:45:45.385+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:45:45.381+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:45:45.420+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:45:45.420+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:45:45.445+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.995 seconds
[2024-01-08T07:46:15.650+0000] {processor.py:161} INFO - Started process (PID=413) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:46:15.653+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:46:15.655+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:46:15.655+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:46:16.616+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:46:16.648+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:46:16.647+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:46:16.696+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:46:16.695+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:46:16.731+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.086 seconds
[2024-01-08T07:46:46.978+0000] {processor.py:161} INFO - Started process (PID=478) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:46:46.981+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:46:46.983+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:46:46.982+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:46:47.823+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:46:47.845+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:46:47.844+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:46:47.875+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:46:47.875+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:46:47.921+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.948 seconds
[2024-01-08T07:47:18.244+0000] {processor.py:161} INFO - Started process (PID=546) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:47:18.245+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:47:18.247+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:47:18.246+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:47:19.020+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:47:19.043+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:47:19.042+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:47:19.071+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:47:19.071+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:47:19.097+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.858 seconds
[2024-01-08T07:47:49.173+0000] {processor.py:161} INFO - Started process (PID=609) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:47:49.176+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:47:49.177+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:47:49.177+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:47:50.067+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:47:50.094+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:47:50.093+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:47:50.125+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:47:50.125+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:47:50.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.986 seconds
[2024-01-08T07:48:21.041+0000] {processor.py:161} INFO - Started process (PID=678) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:48:21.042+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:48:21.044+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:48:21.044+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:48:21.812+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:48:21.834+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:48:21.833+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:48:21.870+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:48:21.869+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:48:21.905+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.871 seconds
[2024-01-08T07:48:52.114+0000] {processor.py:161} INFO - Started process (PID=742) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:48:52.116+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T07:48:52.117+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:48:52.117+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:48:52.894+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T07:48:52.916+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:48:52.916+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T07:48:52.948+0000] {logging_mixin.py:188} INFO - [2024-01-08T07:48:52.948+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-08T00:00:00+00:00, run_after=2024-01-09T00:00:00+00:00
[2024-01-08T07:48:52.975+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.866 seconds
[2024-01-08T11:49:57.326+0000] {processor.py:161} INFO - Started process (PID=32) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:49:57.354+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T11:49:57.358+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:49:57.358+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:50:00.720+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:50:01.128+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:50:01.127+0000] {override.py:1769} INFO - Created Permission View: can read on DAG:etl_to_datalake
[2024-01-08T11:50:01.154+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:50:01.153+0000] {override.py:1769} INFO - Created Permission View: can delete on DAG:etl_to_datalake
[2024-01-08T11:50:01.179+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:50:01.179+0000] {override.py:1769} INFO - Created Permission View: can edit on DAG:etl_to_datalake
[2024-01-08T11:50:01.183+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:50:01.182+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T11:50:01.243+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:50:01.242+0000] {dag.py:3055} INFO - Creating ORM DAG for etl_to_datalake
[2024-01-08T11:50:01.288+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:50:01.288+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T11:50:01.399+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 4.084 seconds
[2024-01-08T11:50:32.042+0000] {processor.py:161} INFO - Started process (PID=97) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:50:32.071+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T11:50:32.076+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:50:32.075+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:50:32.767+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:50:32.787+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:50:32.786+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T11:50:32.815+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:50:32.815+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T11:50:32.839+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.802 seconds
[2024-01-08T11:51:02.933+0000] {processor.py:161} INFO - Started process (PID=156) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:51:02.934+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T11:51:02.937+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:51:02.937+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:51:03.595+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:51:03.614+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:51:03.614+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T11:51:03.641+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:51:03.641+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T11:51:03.665+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.737 seconds
[2024-01-08T11:51:33.746+0000] {processor.py:161} INFO - Started process (PID=215) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:51:33.747+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T11:51:33.750+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:51:33.750+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:51:34.454+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:51:34.474+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:51:34.473+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T11:51:34.495+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:51:34.495+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T11:51:34.514+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.774 seconds
[2024-01-08T11:52:04.797+0000] {processor.py:161} INFO - Started process (PID=274) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:52:04.798+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T11:52:04.801+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:52:04.801+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:52:05.508+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:52:05.525+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:52:05.524+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T11:52:05.552+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:52:05.552+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T11:52:05.570+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.779 seconds
[2024-01-08T11:52:36.108+0000] {processor.py:161} INFO - Started process (PID=333) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:52:36.110+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T11:52:36.113+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:52:36.112+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:52:36.764+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:52:36.783+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:52:36.783+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T11:52:36.806+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:52:36.806+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T11:52:36.827+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.724 seconds
[2024-01-08T11:53:06.870+0000] {processor.py:161} INFO - Started process (PID=391) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:53:06.872+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T11:53:06.874+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:53:06.874+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:53:07.514+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:53:07.534+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:53:07.533+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T11:53:07.557+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:53:07.556+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T11:53:07.582+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.716 seconds
[2024-01-08T11:53:37.965+0000] {processor.py:161} INFO - Started process (PID=450) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:53:37.982+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T11:53:37.985+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:53:37.985+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:53:38.680+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:53:38.699+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:53:38.698+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T11:53:38.721+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:53:38.721+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T11:53:38.744+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.786 seconds
[2024-01-08T11:54:08.875+0000] {processor.py:161} INFO - Started process (PID=513) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:54:08.877+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T11:54:08.880+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:54:08.880+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:54:09.534+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:54:09.554+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:54:09.554+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T11:54:09.579+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:54:09.579+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T11:54:09.598+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.728 seconds
[2024-01-08T11:54:40.308+0000] {processor.py:161} INFO - Started process (PID=572) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:54:40.310+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T11:54:40.314+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:54:40.313+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:54:41.074+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:54:41.094+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:54:41.093+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T11:54:41.119+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:54:41.119+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T11:54:41.140+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.837 seconds
[2024-01-08T11:55:11.202+0000] {processor.py:161} INFO - Started process (PID=635) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:55:11.203+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T11:55:11.206+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:55:11.206+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:55:11.861+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:55:11.881+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:55:11.880+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T11:55:11.904+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:55:11.904+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T11:55:11.923+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.726 seconds
[2024-01-08T11:55:42.642+0000] {processor.py:161} INFO - Started process (PID=694) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:55:42.645+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T11:55:42.648+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:55:42.647+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:55:43.338+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:55:43.358+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:55:43.357+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T11:55:43.384+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:55:43.383+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T11:55:43.404+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.767 seconds
[2024-01-08T11:56:13.587+0000] {processor.py:161} INFO - Started process (PID=757) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:56:13.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T11:56:13.592+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:56:13.591+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:56:14.247+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:56:14.266+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:56:14.265+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T11:56:14.290+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:56:14.290+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T11:56:14.311+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.729 seconds
[2024-01-08T11:56:44.928+0000] {processor.py:161} INFO - Started process (PID=816) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:56:44.931+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T11:56:44.934+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:56:44.934+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:56:45.901+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:56:45.928+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:56:45.927+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T11:56:45.967+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:56:45.967+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T11:56:45.997+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.075 seconds
[2024-01-08T11:57:16.462+0000] {processor.py:161} INFO - Started process (PID=878) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:57:16.463+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T11:57:16.466+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:57:16.466+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:57:17.449+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:57:17.478+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:57:17.477+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T11:57:17.519+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:57:17.518+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T11:57:17.548+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.091 seconds
[2024-01-08T11:57:48.194+0000] {processor.py:161} INFO - Started process (PID=937) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:57:48.198+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T11:57:48.202+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:57:48.201+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:57:49.214+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:57:49.245+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:57:49.244+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T11:57:49.292+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:57:49.291+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T11:57:49.325+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.137 seconds
[2024-01-08T11:58:19.555+0000] {processor.py:161} INFO - Started process (PID=996) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:58:19.558+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T11:58:19.561+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:58:19.560+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:58:20.261+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:58:20.285+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:58:20.284+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T11:58:20.310+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:58:20.309+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T11:58:20.331+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.782 seconds
[2024-01-08T11:58:50.898+0000] {processor.py:161} INFO - Started process (PID=1055) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:58:50.899+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T11:58:50.901+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:58:50.901+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:58:51.603+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:58:51.622+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:58:51.621+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T11:58:51.646+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:58:51.646+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T11:58:51.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.776 seconds
[2024-01-08T11:59:22.182+0000] {processor.py:161} INFO - Started process (PID=1114) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:59:22.217+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T11:59:22.221+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:59:22.221+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:59:22.966+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:59:22.987+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:59:22.987+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T11:59:23.028+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:59:23.027+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T11:59:23.048+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.873 seconds
[2024-01-08T11:59:54.041+0000] {processor.py:161} INFO - Started process (PID=1173) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:59:54.042+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T11:59:54.046+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:59:54.045+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:59:54.719+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T11:59:54.739+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:59:54.738+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T11:59:54.762+0000] {logging_mixin.py:188} INFO - [2024-01-08T11:59:54.762+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T11:59:54.782+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.747 seconds
[2024-01-08T12:00:25.300+0000] {processor.py:161} INFO - Started process (PID=1232) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:00:25.318+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:00:25.322+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:00:25.322+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:00:25.997+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:00:26.018+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:00:26.017+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:00:26.040+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:00:26.040+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:00:26.061+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.767 seconds
[2024-01-08T12:00:56.503+0000] {processor.py:161} INFO - Started process (PID=1291) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:00:56.504+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:00:56.507+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:00:56.507+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:00:57.161+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:00:57.180+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:00:57.179+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:00:57.205+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:00:57.205+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:00:57.223+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.726 seconds
[2024-01-08T12:01:27.976+0000] {processor.py:161} INFO - Started process (PID=1350) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:01:27.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:01:27.980+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:01:27.980+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:01:28.704+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:01:28.731+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:01:28.730+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:01:28.760+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:01:28.760+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:01:28.780+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.811 seconds
[2024-01-08T12:01:58.839+0000] {processor.py:161} INFO - Started process (PID=1408) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:01:58.841+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:01:58.845+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:01:58.845+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:01:59.535+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:01:59.556+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:01:59.556+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:01:59.585+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:01:59.584+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:01:59.606+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.773 seconds
[2024-01-08T12:02:29.753+0000] {processor.py:161} INFO - Started process (PID=1469) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:02:29.755+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:02:29.759+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:02:29.758+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:02:30.432+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:02:30.452+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:02:30.451+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:02:30.484+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:02:30.484+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:02:30.506+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.758 seconds
[2024-01-08T12:03:00.688+0000] {processor.py:161} INFO - Started process (PID=1528) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:03:00.690+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:03:00.693+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:03:00.693+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:03:01.381+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:03:01.401+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:03:01.401+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:03:01.427+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:03:01.426+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:03:01.446+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.763 seconds
[2024-01-08T12:03:31.855+0000] {processor.py:161} INFO - Started process (PID=1587) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:03:31.857+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:03:31.860+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:03:31.860+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:03:32.525+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:03:32.549+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:03:32.549+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:03:32.575+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:03:32.575+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:03:32.596+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.747 seconds
[2024-01-08T12:04:02.856+0000] {processor.py:161} INFO - Started process (PID=1646) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:04:02.858+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:04:02.862+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:04:02.862+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:04:03.418+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:04:03.446+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:04:03.445+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:04:03.487+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:04:03.486+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:04:03.519+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.670 seconds
[2024-01-08T12:04:33.625+0000] {processor.py:161} INFO - Started process (PID=1706) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:04:33.626+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:04:33.630+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:04:33.630+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:04:34.326+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:04:34.351+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:04:34.351+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:04:34.378+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:04:34.378+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:04:34.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.782 seconds
[2024-01-08T12:05:05.182+0000] {processor.py:161} INFO - Started process (PID=1771) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:05:05.185+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:05:05.188+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:05:05.188+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:05:05.853+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:05:05.877+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:05:05.876+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:05:05.913+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:05:05.912+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:05:05.942+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.766 seconds
[2024-01-08T12:05:36.517+0000] {processor.py:161} INFO - Started process (PID=1830) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:05:36.519+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:05:36.522+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:05:36.522+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:05:37.040+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:05:37.063+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:05:37.062+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:05:37.094+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:05:37.093+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:05:37.119+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.608 seconds
[2024-01-08T12:06:08.019+0000] {processor.py:161} INFO - Started process (PID=1889) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:06:08.055+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:06:08.058+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:06:08.057+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:06:08.552+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:06:08.575+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:06:08.574+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:06:08.599+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:06:08.598+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:06:08.621+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.607 seconds
[2024-01-08T12:06:39.325+0000] {processor.py:161} INFO - Started process (PID=1948) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:06:39.326+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:06:39.329+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:06:39.329+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:06:39.783+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:06:39.811+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:06:39.811+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:06:39.840+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:06:39.840+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:06:39.863+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.545 seconds
[2024-01-08T12:07:10.653+0000] {processor.py:161} INFO - Started process (PID=2007) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:07:10.672+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:07:10.676+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:07:10.676+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:07:11.231+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:07:11.264+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:07:11.264+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:07:11.289+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:07:11.289+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:07:11.310+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.664 seconds
[2024-01-08T12:07:42.265+0000] {processor.py:161} INFO - Started process (PID=2066) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:07:42.267+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:07:42.271+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:07:42.270+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:07:43.005+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:07:43.034+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:07:43.034+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:07:43.073+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:07:43.073+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:07:43.100+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.841 seconds
[2024-01-08T12:08:13.664+0000] {processor.py:161} INFO - Started process (PID=2125) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:08:13.666+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:08:13.670+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:08:13.669+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:08:14.271+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:08:14.301+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:08:14.300+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:08:14.340+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:08:14.339+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:08:14.369+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.711 seconds
[2024-01-08T12:08:44.436+0000] {processor.py:161} INFO - Started process (PID=2184) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:08:44.437+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:08:44.440+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:08:44.439+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:08:44.918+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:08:44.942+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:08:44.941+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:08:44.969+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:08:44.968+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:08:44.990+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.559 seconds
[2024-01-08T12:09:15.580+0000] {processor.py:161} INFO - Started process (PID=2243) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:09:15.601+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:09:15.604+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:09:15.603+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:09:16.095+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:09:16.125+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:09:16.124+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:09:16.154+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:09:16.153+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:09:16.180+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.605 seconds
[2024-01-08T12:09:46.950+0000] {processor.py:161} INFO - Started process (PID=2302) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:09:46.952+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:09:46.955+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:09:46.954+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:09:47.434+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:09:47.458+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:09:47.457+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:09:47.490+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:09:47.489+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:09:47.508+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.565 seconds
[2024-01-08T12:10:18.310+0000] {processor.py:161} INFO - Started process (PID=2361) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:10:18.312+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:10:18.317+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:10:18.316+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:10:18.787+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:10:18.809+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:10:18.808+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:10:18.835+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:10:18.835+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:10:18.855+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.550 seconds
[2024-01-08T12:10:49.664+0000] {processor.py:161} INFO - Started process (PID=2420) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:10:49.665+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:10:49.668+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:10:49.668+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:10:50.132+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:10:50.155+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:10:50.154+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:10:50.181+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:10:50.181+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:10:50.202+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.544 seconds
[2024-01-08T12:11:21.155+0000] {processor.py:161} INFO - Started process (PID=2479) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:11:21.188+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:11:21.192+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:11:21.191+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:11:21.658+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:11:21.680+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:11:21.680+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:11:21.910+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:11:21.909+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:11:21.931+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.780 seconds
[2024-01-08T12:11:52.435+0000] {processor.py:161} INFO - Started process (PID=2538) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:11:52.462+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:11:52.467+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:11:52.466+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:11:52.946+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:11:52.970+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:11:52.969+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:11:53.005+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:11:53.004+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:11:53.231+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.803 seconds
[2024-01-08T12:12:23.776+0000] {processor.py:161} INFO - Started process (PID=2597) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:12:23.778+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:12:23.781+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:12:23.781+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:12:24.255+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:12:24.276+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:12:24.275+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:12:24.309+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:12:24.309+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:12:24.524+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.755 seconds
[2024-01-08T12:12:55.304+0000] {processor.py:161} INFO - Started process (PID=2656) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:12:55.306+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:12:55.309+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:12:55.308+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:12:55.766+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:12:55.789+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:12:55.788+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:12:55.826+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:12:55.825+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:12:56.045+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.747 seconds
[2024-01-08T12:13:26.828+0000] {processor.py:161} INFO - Started process (PID=2715) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:13:26.829+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:13:26.832+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:13:26.832+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:13:27.291+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:13:27.315+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:13:27.314+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:13:27.340+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:13:27.340+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:13:27.559+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.738 seconds
[2024-01-08T12:13:58.287+0000] {processor.py:161} INFO - Started process (PID=2774) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:13:58.290+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:13:58.293+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:13:58.292+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:13:58.758+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:13:58.782+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:13:58.782+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:13:58.807+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:13:58.807+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:13:58.829+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.549 seconds
[2024-01-08T12:14:29.856+0000] {processor.py:161} INFO - Started process (PID=2833) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:14:29.857+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:14:29.861+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:14:29.861+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:14:30.334+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:14:30.363+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:14:30.362+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:14:30.388+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:14:30.388+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:14:30.608+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.759 seconds
[2024-01-08T12:15:01.460+0000] {processor.py:161} INFO - Started process (PID=2892) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:15:01.481+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:15:01.485+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:15:01.484+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:15:02.234+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:15:02.265+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:15:02.264+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:15:02.305+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:15:02.305+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:15:02.576+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.123 seconds
[2024-01-08T12:15:33.346+0000] {processor.py:161} INFO - Started process (PID=2952) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:15:33.348+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:15:33.353+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:15:33.353+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:15:33.942+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:15:33.966+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:15:33.966+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:15:34.223+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:15:34.223+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:15:34.249+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.907 seconds
[2024-01-08T12:16:04.657+0000] {processor.py:161} INFO - Started process (PID=3015) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:16:04.659+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:16:04.662+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:16:04.661+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:16:05.178+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:16:05.200+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:16:05.199+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:16:05.435+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:16:05.435+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:16:05.455+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.803 seconds
[2024-01-08T12:16:35.663+0000] {processor.py:161} INFO - Started process (PID=3076) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:16:35.665+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:16:35.668+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:16:35.668+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:16:36.186+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:16:36.216+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:16:36.215+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:16:36.504+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:16:36.503+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:16:36.530+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.872 seconds
[2024-01-08T12:17:06.987+0000] {processor.py:161} INFO - Started process (PID=3141) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:17:06.988+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:17:06.991+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:17:06.990+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:17:07.642+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:17:07.661+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:17:07.661+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:17:07.685+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:17:07.684+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:17:07.703+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.721 seconds
[2024-01-08T12:17:38.361+0000] {processor.py:161} INFO - Started process (PID=3200) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:17:38.363+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:17:38.368+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:17:38.367+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:17:39.085+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:17:39.103+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:17:39.103+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:17:39.126+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:17:39.126+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:17:39.144+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.788 seconds
[2024-01-08T12:18:09.941+0000] {processor.py:161} INFO - Started process (PID=3259) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:18:09.943+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:18:09.947+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:18:09.946+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:18:10.615+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:18:10.636+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:18:10.635+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:18:10.663+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:18:10.663+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:18:10.685+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.748 seconds
[2024-01-08T12:18:41.358+0000] {processor.py:161} INFO - Started process (PID=3318) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:18:41.396+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:18:41.400+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:18:41.399+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:18:42.091+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:18:42.109+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:18:42.109+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:18:42.132+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:18:42.132+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:18:42.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.800 seconds
[2024-01-08T12:19:12.748+0000] {processor.py:161} INFO - Started process (PID=3377) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:19:12.749+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:19:12.751+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:19:12.751+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:19:13.409+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:19:13.429+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:19:13.428+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:19:13.454+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:19:13.454+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:19:13.473+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.732 seconds
[2024-01-08T12:19:44.307+0000] {processor.py:161} INFO - Started process (PID=3436) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:19:44.309+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:19:44.313+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:19:44.313+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:19:45.168+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:19:45.188+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:19:45.188+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:19:45.214+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:19:45.214+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:19:45.235+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.934 seconds
[2024-01-08T12:20:15.819+0000] {processor.py:161} INFO - Started process (PID=3495) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:20:15.822+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:20:15.826+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:20:15.826+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:20:16.821+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:20:16.850+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:20:16.849+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:20:16.883+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:20:16.883+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:20:16.909+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.096 seconds
[2024-01-08T12:20:47.011+0000] {processor.py:161} INFO - Started process (PID=3554) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:20:47.013+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:20:47.016+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:20:47.015+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:20:47.717+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:20:47.738+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:20:47.737+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:20:47.759+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:20:47.759+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:20:47.781+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.775 seconds
[2024-01-08T12:21:17.861+0000] {processor.py:161} INFO - Started process (PID=3613) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:21:17.863+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:21:17.866+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:21:17.866+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:21:18.524+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:21:18.549+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:21:18.548+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:21:18.577+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:21:18.577+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:21:18.595+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.739 seconds
[2024-01-08T12:21:49.546+0000] {processor.py:161} INFO - Started process (PID=3672) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:21:49.549+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:21:49.553+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:21:49.553+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:21:50.265+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:21:50.287+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:21:50.286+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:21:50.310+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:21:50.310+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:21:50.331+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.791 seconds
[2024-01-08T12:22:21.080+0000] {processor.py:161} INFO - Started process (PID=3731) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:22:21.082+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:22:21.086+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:22:21.085+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:22:21.768+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:22:21.789+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:22:21.788+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:22:21.813+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:22:21.812+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:22:21.833+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.759 seconds
[2024-01-08T12:22:52.727+0000] {processor.py:161} INFO - Started process (PID=3790) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:22:52.728+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:22:52.731+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:22:52.731+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:22:53.403+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:22:53.423+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:22:53.423+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:22:53.446+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:22:53.446+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:22:53.464+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.743 seconds
[2024-01-08T12:23:24.210+0000] {processor.py:161} INFO - Started process (PID=3849) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:23:24.240+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:23:24.243+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:23:24.243+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:23:24.919+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:23:24.939+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:23:24.939+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:23:24.962+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:23:24.962+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:23:24.987+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.782 seconds
[2024-01-08T12:23:55.684+0000] {processor.py:161} INFO - Started process (PID=3908) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:23:55.685+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:23:55.689+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:23:55.688+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:23:56.362+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:23:56.382+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:23:56.381+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:23:56.405+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:23:56.405+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:23:56.427+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.748 seconds
[2024-01-08T12:24:27.312+0000] {processor.py:161} INFO - Started process (PID=3967) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:24:27.321+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:24:27.326+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:24:27.326+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:24:28.086+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:24:28.106+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:24:28.106+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:24:28.134+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:24:28.133+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:24:28.161+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.853 seconds
[2024-01-08T12:24:58.896+0000] {processor.py:161} INFO - Started process (PID=4027) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:24:58.898+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:24:58.901+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:24:58.900+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:24:59.587+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:24:59.607+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:24:59.606+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:24:59.632+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:24:59.631+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:24:59.650+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.759 seconds
[2024-01-08T12:25:30.418+0000] {processor.py:161} INFO - Started process (PID=4086) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:25:30.420+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:25:30.423+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:25:30.423+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:25:31.307+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:25:31.328+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:25:31.327+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:25:31.367+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:25:31.367+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:25:31.394+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.983 seconds
[2024-01-08T12:26:01.583+0000] {processor.py:161} INFO - Started process (PID=4145) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:26:01.584+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:26:01.587+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:26:01.586+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:26:02.248+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:26:02.271+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:26:02.270+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:26:02.293+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:26:02.293+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:26:02.311+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.733 seconds
[2024-01-08T12:26:32.355+0000] {processor.py:161} INFO - Started process (PID=4203) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:26:32.369+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:26:32.372+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:26:32.372+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:26:33.030+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:26:33.050+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:26:33.049+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:26:33.073+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:26:33.073+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:26:33.091+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.742 seconds
[2024-01-08T12:27:03.133+0000] {processor.py:161} INFO - Started process (PID=4262) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:27:03.134+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:27:03.137+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:27:03.137+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:27:03.762+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:27:03.780+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:27:03.779+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:27:03.802+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:27:03.802+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:27:03.821+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.693 seconds
[2024-01-08T12:27:34.661+0000] {processor.py:161} INFO - Started process (PID=4321) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:27:34.705+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:27:34.708+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:27:34.707+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:27:35.408+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:27:35.427+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:27:35.427+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:27:35.453+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:27:35.453+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:27:35.474+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.818 seconds
[2024-01-08T12:28:05.616+0000] {processor.py:161} INFO - Started process (PID=4386) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:28:05.617+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:28:05.620+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:28:05.620+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:28:06.308+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:28:06.327+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:28:06.327+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:28:06.349+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:28:06.349+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:28:06.373+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.762 seconds
[2024-01-08T12:28:36.491+0000] {processor.py:161} INFO - Started process (PID=4451) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:28:36.493+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:28:36.496+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:28:36.496+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:28:37.184+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:28:37.203+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:28:37.202+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:28:37.227+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:28:37.227+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:28:37.249+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.762 seconds
[2024-01-08T12:29:07.291+0000] {processor.py:161} INFO - Started process (PID=4515) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:29:07.292+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:29:07.294+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:29:07.294+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:29:07.941+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:29:07.959+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:29:07.958+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:29:07.979+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:29:07.979+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:29:07.996+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.710 seconds
[2024-01-08T12:29:38.457+0000] {processor.py:161} INFO - Started process (PID=4581) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:29:38.460+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:29:38.465+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:29:38.464+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:29:39.120+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:29:39.137+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:29:39.137+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:29:39.158+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:29:39.158+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:29:39.175+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.723 seconds
[2024-01-08T12:30:09.965+0000] {processor.py:161} INFO - Started process (PID=4642) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:30:09.966+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:30:09.969+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:30:09.969+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:30:10.631+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:30:10.653+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:30:10.652+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:30:10.675+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:30:10.674+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:30:10.692+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.732 seconds
[2024-01-08T12:30:41.469+0000] {processor.py:161} INFO - Started process (PID=4704) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:30:41.471+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:30:41.475+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:30:41.475+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:30:42.165+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:30:42.184+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:30:42.184+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:30:42.206+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:30:42.206+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:30:42.222+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.758 seconds
[2024-01-08T12:31:12.680+0000] {processor.py:161} INFO - Started process (PID=4763) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:31:12.682+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:31:12.685+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:31:12.685+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:31:13.555+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:31:13.585+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:31:13.584+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:31:13.624+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:31:13.624+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:31:13.651+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.978 seconds
[2024-01-08T12:31:44.148+0000] {processor.py:161} INFO - Started process (PID=4822) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:31:44.150+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:31:44.153+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:31:44.152+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:31:44.857+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:31:44.876+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:31:44.875+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:31:44.898+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:31:44.898+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:31:44.915+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.773 seconds
[2024-01-08T12:32:15.573+0000] {processor.py:161} INFO - Started process (PID=4881) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:32:15.574+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:32:15.577+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:32:15.576+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:32:16.201+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:32:16.221+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:32:16.220+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:32:16.245+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:32:16.245+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:32:16.263+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.695 seconds
[2024-01-08T12:32:46.310+0000] {processor.py:161} INFO - Started process (PID=4939) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:32:46.321+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:32:46.324+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:32:46.324+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:32:46.948+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:32:46.965+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:32:46.964+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:32:46.987+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:32:46.986+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:32:47.002+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.696 seconds
[2024-01-08T12:33:17.509+0000] {processor.py:161} INFO - Started process (PID=4999) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:33:17.510+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:33:17.513+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:33:17.512+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:33:18.141+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:33:18.159+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:33:18.159+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:33:18.183+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:33:18.182+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:33:18.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.697 seconds
[2024-01-08T12:33:49.030+0000] {processor.py:161} INFO - Started process (PID=5058) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:33:49.069+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:33:49.072+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:33:49.072+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:33:49.680+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:33:49.697+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:33:49.696+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:33:49.718+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:33:49.718+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:33:49.737+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.713 seconds
[2024-01-08T12:34:20.529+0000] {processor.py:161} INFO - Started process (PID=5117) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:34:20.530+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:34:20.533+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:34:20.533+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:34:21.168+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:34:21.192+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:34:21.191+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:34:21.215+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:34:21.215+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:34:21.235+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.713 seconds
[2024-01-08T12:34:51.714+0000] {processor.py:161} INFO - Started process (PID=5176) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:34:51.717+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:34:51.720+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:34:51.720+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:34:52.629+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:34:52.653+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:34:52.652+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:34:52.688+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:34:52.687+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:34:52.710+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.002 seconds
[2024-01-08T12:35:23.126+0000] {processor.py:161} INFO - Started process (PID=5235) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:35:23.127+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:35:23.130+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:35:23.130+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:35:24.041+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:35:24.066+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:35:24.065+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:35:24.102+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:35:24.102+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:35:24.128+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.009 seconds
[2024-01-08T12:35:54.671+0000] {processor.py:161} INFO - Started process (PID=5294) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:35:54.673+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:35:54.676+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:35:54.675+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:35:55.350+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:35:55.368+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:35:55.368+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:35:55.396+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:35:55.396+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:35:55.414+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.748 seconds
[2024-01-08T12:36:26.080+0000] {processor.py:161} INFO - Started process (PID=5353) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:36:26.082+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:36:26.085+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:36:26.085+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:36:26.698+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:36:26.717+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:36:26.717+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:36:26.740+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:36:26.740+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:36:26.756+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.683 seconds
[2024-01-08T12:36:57.497+0000] {processor.py:161} INFO - Started process (PID=5412) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:36:57.498+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:36:57.501+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:36:57.501+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:36:58.150+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:36:58.173+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:36:58.172+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:36:58.197+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:36:58.196+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:36:58.213+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.723 seconds
[2024-01-08T12:37:28.897+0000] {processor.py:161} INFO - Started process (PID=5471) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:37:28.910+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:37:28.912+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:37:28.912+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:37:29.522+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:37:29.540+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:37:29.539+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:37:29.562+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:37:29.562+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:37:29.582+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.692 seconds
[2024-01-08T12:38:00.074+0000] {processor.py:161} INFO - Started process (PID=5530) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:38:00.075+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T12:38:00.078+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:38:00.078+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:38:00.694+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T12:38:00.713+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:38:00.712+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T12:38:00.734+0000] {logging_mixin.py:188} INFO - [2024-01-08T12:38:00.734+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T12:38:00.753+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.683 seconds
[2024-01-08T13:29:50.306+0000] {processor.py:161} INFO - Started process (PID=31) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:29:50.317+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:29:50.319+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:29:50.319+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:29:52.568+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:29:52.827+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:29:52.826+0000] {override.py:1769} INFO - Created Permission View: can read on DAG:etl_to_datalake
[2024-01-08T13:29:52.840+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:29:52.839+0000] {override.py:1769} INFO - Created Permission View: can delete on DAG:etl_to_datalake
[2024-01-08T13:29:52.846+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:29:52.846+0000] {override.py:1769} INFO - Created Permission View: can edit on DAG:etl_to_datalake
[2024-01-08T13:29:52.848+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:29:52.847+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:29:52.865+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:29:52.864+0000] {dag.py:3055} INFO - Creating ORM DAG for etl_to_datalake
[2024-01-08T13:29:52.877+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:29:52.877+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:29:52.903+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 2.611 seconds
[2024-01-08T13:30:23.303+0000] {processor.py:161} INFO - Started process (PID=90) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:30:23.364+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:30:23.366+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:30:23.365+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:30:23.894+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:30:23.909+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:30:23.909+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:30:23.931+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:30:23.931+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:30:23.947+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.647 seconds
[2024-01-08T13:30:53.991+0000] {processor.py:161} INFO - Started process (PID=149) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:30:53.992+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:30:53.993+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:30:53.993+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:30:54.495+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:30:54.508+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:30:54.508+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:30:54.526+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:30:54.526+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:30:54.542+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.553 seconds
[2024-01-08T13:31:25.066+0000] {processor.py:161} INFO - Started process (PID=208) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:31:25.084+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:31:25.087+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:31:25.086+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:31:25.572+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:31:25.587+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:31:25.586+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:31:25.605+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:31:25.604+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:31:25.620+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.556 seconds
[2024-01-08T13:31:56.039+0000] {processor.py:161} INFO - Started process (PID=267) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:31:56.040+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:31:56.042+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:31:56.041+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:31:56.558+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:31:56.574+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:31:56.573+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:31:56.594+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:31:56.594+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:31:56.614+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.579 seconds
[2024-01-08T13:32:26.757+0000] {processor.py:161} INFO - Started process (PID=326) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:32:26.773+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:32:26.775+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:32:26.775+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:32:27.292+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:32:27.313+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:32:27.312+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:32:27.336+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:32:27.336+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:32:27.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.600 seconds
[2024-01-08T13:36:26.183+0000] {processor.py:161} INFO - Started process (PID=30) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:36:26.198+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:36:26.202+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:36:26.202+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:36:27.621+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:36:27.619+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 14, in <module>
    sys.path.append(os.path.join(os.path.dirname(__file__), '../data/'))
NameError: name 'sys' is not defined
[2024-01-08T13:36:27.622+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:36:27.668+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.498 seconds
[2024-01-08T13:36:57.908+0000] {processor.py:161} INFO - Started process (PID=89) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:36:57.953+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:36:57.955+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:36:57.954+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:36:58.542+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:36:58.541+0000] {dagbag.py:348} ERROR - Failed to import: /opt/airflow/dags/etl_to_datalake.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 344, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/etl_to_datalake.py", line 14, in <module>
    sys.path.append(os.path.join(os.path.dirname(__file__), '../data/'))
NameError: name 'sys' is not defined
[2024-01-08T13:36:58.543+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:36:58.560+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.655 seconds
[2024-01-08T13:40:47.473+0000] {processor.py:161} INFO - Started process (PID=30) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:40:47.496+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:40:47.498+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:40:47.498+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:40:48.807+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:40:49.124+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:40:49.123+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:40:49.190+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:40:49.190+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:40:49.271+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 1.810 seconds
[2024-01-08T13:41:19.802+0000] {processor.py:161} INFO - Started process (PID=89) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:41:19.835+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:41:19.838+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:41:19.838+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:41:20.416+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:41:20.445+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:41:20.444+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:41:20.470+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:41:20.470+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:41:20.489+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.690 seconds
[2024-01-08T13:41:50.649+0000] {processor.py:161} INFO - Started process (PID=148) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:41:50.650+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:41:50.652+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:41:50.652+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:41:51.172+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:41:51.190+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:41:51.189+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:41:51.213+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:41:51.213+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:41:51.234+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.588 seconds
[2024-01-08T13:42:21.429+0000] {processor.py:161} INFO - Started process (PID=206) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:42:21.430+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:42:21.432+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:42:21.432+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:42:21.978+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:42:21.997+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:42:21.996+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:42:22.021+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:42:22.021+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:42:22.039+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.612 seconds
[2024-01-08T13:42:52.089+0000] {processor.py:161} INFO - Started process (PID=265) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:42:52.091+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:42:52.093+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:42:52.092+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:42:52.603+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:42:52.621+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:42:52.620+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:42:52.641+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:42:52.640+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:42:52.658+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.572 seconds
[2024-01-08T13:43:22.959+0000] {processor.py:161} INFO - Started process (PID=324) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:43:22.974+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:43:22.976+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:43:22.976+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:43:23.508+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:43:23.527+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:43:23.527+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:43:23.549+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:43:23.549+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:43:23.564+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.609 seconds
[2024-01-08T13:43:53.681+0000] {processor.py:161} INFO - Started process (PID=389) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:43:53.683+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:43:53.685+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:43:53.685+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:43:54.177+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:43:54.193+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:43:54.192+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:43:54.213+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:43:54.213+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:43:54.231+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.553 seconds
[2024-01-08T13:44:25.151+0000] {processor.py:161} INFO - Started process (PID=448) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:44:25.153+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:44:25.155+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:44:25.155+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:44:25.677+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:44:25.693+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:44:25.692+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:44:25.714+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:44:25.714+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:44:25.734+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.586 seconds
[2024-01-08T13:44:56.562+0000] {processor.py:161} INFO - Started process (PID=507) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:44:56.571+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:44:56.573+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:44:56.573+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:44:57.079+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:44:57.100+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:44:57.099+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:44:57.127+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:44:57.127+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:44:57.145+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.586 seconds
[2024-01-08T13:45:27.796+0000] {processor.py:161} INFO - Started process (PID=566) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:45:27.797+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:45:27.798+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:45:27.798+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:45:28.312+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:45:28.328+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:45:28.326+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:45:28.347+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:45:28.347+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:45:28.366+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.573 seconds
[2024-01-08T13:45:59.189+0000] {processor.py:161} INFO - Started process (PID=625) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:45:59.202+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:45:59.203+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:45:59.203+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:45:59.725+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:45:59.745+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:45:59.744+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:45:59.770+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:45:59.770+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:45:59.789+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.603 seconds
[2024-01-08T13:46:29.941+0000] {processor.py:161} INFO - Started process (PID=684) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:46:29.943+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:46:29.946+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:46:29.945+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:46:30.554+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:46:30.580+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:46:30.579+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:46:30.605+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:46:30.604+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:46:30.627+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.690 seconds
[2024-01-08T13:47:01.263+0000] {processor.py:161} INFO - Started process (PID=750) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:47:01.265+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:47:01.268+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:47:01.267+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:47:01.891+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:47:01.913+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:47:01.912+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:47:01.935+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:47:01.935+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:47:01.956+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.723 seconds
[2024-01-08T13:47:32.867+0000] {processor.py:161} INFO - Started process (PID=809) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:47:32.870+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:47:32.872+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:47:32.872+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:47:33.677+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:47:33.704+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:47:33.703+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:47:33.738+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:47:33.737+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:47:33.763+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.898 seconds
[2024-01-08T13:48:04.361+0000] {processor.py:161} INFO - Started process (PID=868) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:48:04.363+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:48:04.365+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:48:04.365+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:48:04.912+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:48:04.929+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:48:04.928+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:48:04.949+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:48:04.949+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:48:04.967+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.610 seconds
[2024-01-08T13:48:35.754+0000] {processor.py:161} INFO - Started process (PID=927) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:48:35.754+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:48:35.756+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:48:35.756+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:48:36.287+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:48:36.304+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:48:36.304+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:48:36.324+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:48:36.324+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:48:36.342+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.591 seconds
[2024-01-08T13:49:06.393+0000] {processor.py:161} INFO - Started process (PID=986) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:49:06.421+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:49:06.423+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:49:06.422+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:49:06.934+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:49:06.954+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:49:06.954+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:49:06.976+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:49:06.976+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:49:06.996+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.607 seconds
[2024-01-08T13:49:37.698+0000] {processor.py:161} INFO - Started process (PID=1045) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:49:37.699+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:49:37.701+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:49:37.701+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:49:38.246+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:49:38.266+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:49:38.266+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:49:38.288+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:49:38.288+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:49:38.309+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.613 seconds
[2024-01-08T13:50:08.461+0000] {processor.py:161} INFO - Started process (PID=1108) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:50:08.463+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:50:08.465+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:50:08.464+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:50:09.032+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:50:09.052+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:50:09.051+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:50:09.071+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:50:09.071+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:50:09.086+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.628 seconds
[2024-01-08T13:50:39.209+0000] {processor.py:161} INFO - Started process (PID=1172) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:50:39.210+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:50:39.212+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:50:39.212+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:50:39.735+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:50:39.753+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:50:39.752+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:50:39.771+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:50:39.771+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:50:39.788+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.582 seconds
[2024-01-08T13:51:10.389+0000] {processor.py:161} INFO - Started process (PID=1232) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:51:10.391+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:51:10.393+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:51:10.393+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:51:10.920+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:51:10.937+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:51:10.937+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:51:10.956+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:51:10.956+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:51:10.974+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.588 seconds
[2024-01-08T13:51:41.563+0000] {processor.py:161} INFO - Started process (PID=1291) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:51:41.565+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:51:41.568+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:51:41.568+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:51:42.122+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:51:42.140+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:51:42.139+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:51:42.159+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:51:42.159+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:51:42.178+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.619 seconds
[2024-01-08T13:52:12.905+0000] {processor.py:161} INFO - Started process (PID=1352) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:52:12.906+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:52:12.908+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:52:12.907+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:52:13.428+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:52:13.445+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:52:13.445+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:52:13.465+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:52:13.464+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:52:13.485+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.583 seconds
[2024-01-08T13:52:44.190+0000] {processor.py:161} INFO - Started process (PID=1411) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:52:44.192+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:52:44.194+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:52:44.194+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:52:44.709+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:52:44.726+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:52:44.725+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:52:44.744+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:52:44.744+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:52:44.763+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.576 seconds
[2024-01-08T13:53:15.615+0000] {processor.py:161} INFO - Started process (PID=1470) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:53:15.617+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:53:15.619+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:53:15.619+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:53:16.183+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:53:16.210+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:53:16.209+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:53:16.238+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:53:16.238+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:53:16.260+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.648 seconds
[2024-01-08T13:53:47.198+0000] {processor.py:161} INFO - Started process (PID=1529) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:53:47.200+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:53:47.203+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:53:47.202+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:53:47.738+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:53:47.756+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:53:47.755+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:53:47.777+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:53:47.776+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:53:47.800+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.605 seconds
[2024-01-08T13:54:17.863+0000] {processor.py:161} INFO - Started process (PID=1588) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:54:17.863+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:54:17.865+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:54:17.865+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:54:18.389+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:54:18.406+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:54:18.406+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:54:18.427+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:54:18.426+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:54:18.446+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.586 seconds
[2024-01-08T13:54:49.175+0000] {processor.py:161} INFO - Started process (PID=1647) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:54:49.194+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:54:49.196+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:54:49.196+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:54:49.717+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:54:49.737+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:54:49.736+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:54:49.757+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:54:49.756+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:54:49.774+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.603 seconds
[2024-01-08T13:55:19.815+0000] {processor.py:161} INFO - Started process (PID=1706) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:55:19.816+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:55:19.818+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:55:19.817+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:55:20.343+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:55:20.359+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:55:20.359+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:55:20.378+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:55:20.378+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:55:20.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.589 seconds
[2024-01-08T13:55:51.002+0000] {processor.py:161} INFO - Started process (PID=1765) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:55:51.012+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:55:51.014+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:55:51.013+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:55:51.587+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:55:51.608+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:55:51.607+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:55:51.637+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:55:51.637+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:55:51.657+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.659 seconds
[2024-01-08T13:56:22.623+0000] {processor.py:161} INFO - Started process (PID=1824) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:56:22.624+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:56:22.626+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:56:22.626+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:56:23.144+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:56:23.163+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:56:23.162+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:56:23.181+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:56:23.181+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:56:23.200+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.580 seconds
[2024-01-08T13:56:53.312+0000] {processor.py:161} INFO - Started process (PID=1883) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:56:53.321+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:56:53.323+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:56:53.323+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:56:53.883+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:56:53.901+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:56:53.901+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:56:53.919+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:56:53.919+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:56:53.940+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.631 seconds
[2024-01-08T13:57:23.986+0000] {processor.py:161} INFO - Started process (PID=1942) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:57:23.987+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:57:23.989+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:57:23.989+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:57:24.594+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:57:24.613+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:57:24.612+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:57:24.632+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:57:24.632+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:57:24.649+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.667 seconds
[2024-01-08T13:57:54.866+0000] {processor.py:161} INFO - Started process (PID=2001) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:57:54.898+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:57:54.901+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:57:54.900+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:57:55.523+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:57:55.546+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:57:55.545+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:57:55.573+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:57:55.573+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:57:55.593+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.729 seconds
[2024-01-08T13:58:26.163+0000] {processor.py:161} INFO - Started process (PID=2060) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:58:26.164+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:58:26.166+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:58:26.165+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:58:26.698+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:58:26.714+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:58:26.714+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:58:26.735+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:58:26.735+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:58:26.760+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.600 seconds
[2024-01-08T13:58:57.409+0000] {processor.py:161} INFO - Started process (PID=2119) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:58:57.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:58:57.413+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:58:57.412+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:58:57.942+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:58:57.960+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:58:57.959+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:58:57.979+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:58:57.979+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:58:57.995+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.589 seconds
[2024-01-08T13:59:28.595+0000] {processor.py:161} INFO - Started process (PID=2178) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:59:28.596+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:59:28.598+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:59:28.598+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:59:29.106+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:59:29.122+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:59:29.121+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T13:59:29.140+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:59:29.140+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T13:59:29.156+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.564 seconds
[2024-01-08T13:59:59.589+0000] {processor.py:161} INFO - Started process (PID=2237) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T13:59:59.590+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T13:59:59.592+0000] {logging_mixin.py:188} INFO - [2024-01-08T13:59:59.592+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T14:00:00.135+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T14:00:00.160+0000] {logging_mixin.py:188} INFO - [2024-01-08T14:00:00.159+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T14:00:00.185+0000] {logging_mixin.py:188} INFO - [2024-01-08T14:00:00.184+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T14:00:00.206+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.621 seconds
[2024-01-08T14:00:30.883+0000] {processor.py:161} INFO - Started process (PID=2296) to work on /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T14:00:30.885+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/etl_to_datalake.py for tasks to queue
[2024-01-08T14:00:30.888+0000] {logging_mixin.py:188} INFO - [2024-01-08T14:00:30.888+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T14:00:31.629+0000] {processor.py:840} INFO - DAG(s) 'etl_to_datalake' retrieved from /opt/airflow/dags/etl_to_datalake.py
[2024-01-08T14:00:31.653+0000] {logging_mixin.py:188} INFO - [2024-01-08T14:00:31.652+0000] {dag.py:3033} INFO - Sync 1 DAGs
[2024-01-08T14:00:31.680+0000] {logging_mixin.py:188} INFO - [2024-01-08T14:00:31.680+0000] {dag.py:3820} INFO - Setting next_dagrun for etl_to_datalake to 2024-01-06T00:00:00+00:00, run_after=2024-01-07T00:00:00+00:00
[2024-01-08T14:00:31.700+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/etl_to_datalake.py took 0.820 seconds
